{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain_core langchain_openai langgraph langchain_community "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pdfloader uses pypdf internally \n",
    "! pip install pypdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='WHAT IS A BUDGET?\\nAs per Article 112 of the Constitution, Budget is known as Annual Financial Statement of the \\nGovernment.\\nThe term ‚ÄòBudget‚Äô is not mentioned in the Constitution.\\nIt is the statement of estimated receipts and expenditure of the Government in a financial year.\\nUnion Budget is classified into Revenue Budget(including Tax and Non-Tax revenue receipts and \\nexpenditure of the government) and Capital Budget (including capital receipts and payments of \\nthe government).\\nPreparation of budget:\\nDepartment of Economic Affairs, Ministry of Finance is the nodal body responsible for \\npreparing of the Budget.\\nBudget for a year is prepared by the Budget Division of Department of Economic Affairs.\\nIt is prepared broadly on the basis of detailed estimates of expenditure and receipts \\nreceived from various Departments/Ministries and its own subordinate estimating \\nauthorities.\\nBudget is prepared on Cash Basis (i.e. whatever is expected to be actually received or paid \\nunder proper sanction during a financial year).\\nPresentation of budget:\\nPresident in every financial year cause to be laid before both the                                                                                        \\nHouses of Parliament the annual financial statement.\\nIn the Parliament, the budget is presented by the Union Finance                                                                                  \\nMinister, in two parts consisting of Part A and B.\\nPart A: It is the macroeconomic part of the budget where various                                                        \\nschemes and priorities of government are announced, and                                                                 \\nallocations are made to several sectors.\\nPart B: It deals with Finance Bill, which contains taxation proposals such as income tax \\nrevisions and indirect taxes.\\nMajor budget documents: Apart from the Finance Minister‚Äôs Budget Speech, following documents \\nare presented to Parliament:\\nAnnual Financial Statement (under Article 112) ,\\nDemands for Grants (under Article 113),\\nFinance Bill (under article 110)\\nFiscal Policy Statements mandated under FRBM Act -\\nMacro-Economic Framework Statement.\\nMedium-Term Fiscal Policy cum Fiscal Policy Strategy Statement.\\nOther explanatory documents are also presented like:\\nExpenditure Budget\\nReceipt Budget\\nExpenditure Profile\\nBudget at a Glance\\nKey Features of Budget 2024-25\\nImplementation of Budget Announcements, 2023-24\\nONLINE  |  DELHI  |  AHMEDABAD  |  BHOPAL  |  CHANDIGARH  |  GUWAHATI  |  HYDERABAD  |  JAIPUR  |  JODHPUR  |  LUCKNOW  |  PRAYAGRAJ  |  PUNE  |  RANCHI  |  SIKAR 1\\n2024-25\\nUNION  INTERIM\\nSUMMARY OF'), Document(metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='As per Article 112 of the Constitution, Budget is known as Annual Financial Statement of the \\nGovernment.\\nThe term ‚ÄòBudget‚Äô is not mentioned in the Constitution.\\nIt is the statement of estimated receipts and expenditure of the Government in a financial year.\\nUnion Budget is classified into Revenue Budget(including Tax and Non-Tax revenue receipts and \\nexpenditure of the government) and Capital Budget (including capital receipts and payments of \\nthe government).\\nPreparation of budget:\\nDepartment of Economic Affairs, Ministry of Finance is the nodal body responsible for \\npreparing of the Budget.\\nBudget for a year is prepared by the Budget Division of Department of Economic Affairs.\\nIt is prepared broadly on the basis of detailed estimates of expenditure and receipts \\nreceived from various Departments/Ministries and its own subordinate estimating \\nauthorities.\\nBudget is prepared on Cash Basis (i.e. whatever is expected to be actually received or paid \\nunder proper sanction during a financial year).\\nPresentation of budget:\\nPresident in every financial year cause to be laid before both the                                                                                        \\nHouses of Parliament the annual financial statement.\\nIn the Parliament, the budget is presented by the Union Finance                                                                                  \\nMinister, in two parts consisting of Part A and B.\\nPart A: It is the macroeconomic part of the budget where various                                                        \\nschemes and priorities of government are announced, and                                                                 \\nallocations are made to several sectors.\\nPart B: It deals with Finance Bill, which contains taxation proposals such as income tax \\nrevisions and indirect taxes.\\nMajor budget documents: Apart from the Finance Minister‚Äôs Budget Speech, following documents \\nare presented to Parliament:\\nAnnual Financial Statement (under Article 112) ,\\nDemands for Grants (under Article 113),\\nFinance Bill (under article 110)\\nFiscal Policy Statements mandated under FRBM Act -\\nMacro-Economic Framework Statement.\\nMedium-Term Fiscal Policy cum Fiscal Policy Strategy Statement.\\nOther explanatory documents are also presented like:\\nExpenditure Budget\\nReceipt Budget\\nExpenditure Profile\\nBudget at a Glance\\nKey Features of Budget 2024-25\\nImplementation of Budget Announcements, 2023-24\\nUnion Interim Budget 2024-25\\nONLINE  |  DELHI  |  AHMEDABAD  |  BHOPAL  |  CHANDIGARH  |  GUWAHATI  |  HYDERABAD  |  JAIPUR  |  JODHPUR  |  LUCKNOW  |  PRAYAGRAJ  |  PUNE  |  RANCHI  |  SIKAR 2\\nHISTORY OF BUDGET\\nPre Independence:\\nBudget was first introduced on 7th \\nApril, 1860, two years after the \\ntransfer of Indian administration from  \\nEast-India Company to British Crown.\\nThe first Finance Member, who \\npresented the Budget, was James \\nWilson.\\nMr Liaquat Ali Khan, member of the \\ninterim Government presented the \\nbudget of 1947-48.\\nPost-Independence:\\nIndia‚Äôs first Finance Minister Shri R.K. \\nShanmukham Chetty, presented the \\nfirst Budget on 26th November, 1947.\\nSince then, the process of budget \\nhas evolved and emerged as a \\ncrucial tool for Public Finance \\nManagement and reflect the \\nstrength of our democratic \\nprocesses in shaping our economy.\\nBUDGET'), Document(metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content=\"BUDGET PROCESS\\nINTERIM BUDGET 2024-25\\nGeneral Discussuion \\non Budget in both the \\nHouses\\nDetalied discussion and \\nvoting on Demand for \\nGrants in Lok sabha \\nBudget is\\npresented\\nStanding Committees \\nscrutinise individual ministers' \\nDemand for  Grants\\nAppropriation and \\nFinance Bill passed\\nSince 2024 is an election year, instead of a normal budget, an interim budget will be presented \\nthis year.\\nInterim budget: It is a short-term financial plan that covers government expenses until the \\nelections.\\nUnlike a normal budget, which covers every aspect of government finances, including revenues, \\nexpenditures, allocations, and policy statements, interim budget only outlines the government‚Äôs \\nanticipated revenues and expenses until the new government is formed.\\nAs part of Interim budget, the Parliament passes a vote-on-account.\\nVote-on-account : According to Article 116 of the Constitution, a vote-on-account represents an \\nadvance payment to the government from the Consolidated Fund of India, for meeting immediate \\nexpenditure requirements.\\nUnion Interim Budget 2024-25\\nTHE ENTIRE PROCESS IS COMPLETED IN THE FOLLOWING STEPS-\\nONLINE  |  DELHI  |  AHMEDABAD  |  BHOPAL  |  CHANDIGARH  |  GUWAHATI  |  HYDERABAD  |  JAIPUR  |  JODHPUR  |  LUCKNOW  |  PRAYAGRAJ  |  PUNE  |  RANCHI  |  SIKAR 3\"), Document(metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content=\"Vision of Budget: Viksit Bharat by 2047 ‚ÄúProsperous \\nBharat in harmony with nature, modern infrastructure \\nand opportunities for all‚Äù\\nDevelopment Mantra of Budget: Sabka Saath, Sabka \\nVikas, and Sabka Vishwas‚Äô whole of nation‚Äô approach of \\n‚ÄòSabka Prayas‚Äô.\\nPhilosophy is to cover all elements of inclusivity.\\nSocial inclusivity- through coverage of all strata \\nof the society,\\nGeographical inclusivity- through development of \\nall regions of the country.\\nONLINE  |  DELHI  |  AHMEDABAD  |  BHOPAL  |  CHANDIGARH  |  GUWAHATI  |  HYDERABAD  |  JAIPUR  |  JODHPUR  |  LUCKNOW  |  PRAYAGRAJ  |  PUNE  |  RANCHI  |  SIKAR 4\\nBUDGET 2024-25\\nFOCUS AREAS \\nKEY ACHIEVEMENTS IN FOCUS AREAS:\\nSabka Saath,\\nSabka Vikas\\nSabka Saath,\\nSabka Vikas,\\nSabka Vishwas\\nDeveloped India\\n@2047\\nPART A\\n‚ÄòGarib‚Äô\\n(Poor)\\nMahilayen‚Äô\\n(Women)\\n‚ÄòYuva‚Äô\\n(Youth or\\nAmrit\\nPeedhi)\\n‚ÄòAnnadata‚Äô\\n(Farmer)\\nGarib (Poor)\\nAlleviation of poverty: 25 crore people got freedom from multi-dimensional poverty.\\nDirect Benefit Transfer: 34 lakh crore DBT using PM-Jan Dhan accounts has led to savings of \\n2.7 lakh crore for the Government. \\nPM-SVANidhi \\nCredit assistance provided to 78 lakh street vendors. \\n2.3 lakh have received credit for the third time. \\nPM-JANMAN Yojana: Helped in reaching out to the particularly vulnerable tribal groups. \\nPM-Vishwakarma Yojana: Provided end-to-end support to artisans and craftspeople \\nengaged in 18 trades. \\nComprehensive\\ndevelopment of all\\nTrinity of \\ndemography, \\ndemocracy and \\ndiversity, backed \\nby 'Sabka Prayas'\\nUnion Interim Budget 2024-25\"), Document(metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='ONLINE  |  DELHI  |  AHMEDABAD  |  BHOPAL  |  CHANDIGARH  |  GUWAHATI  |  HYDERABAD  |  JAIPUR  |  JODHPUR  |  LUCKNOW  |  PRAYAGRAJ  |  PUNE  |  RANCHI  |  SIKAR 5\\nMahilayen (Women)\\nThirty crore Mudra Yojana loans have been given to \\nwomen entrepreneurs.\\nFemale enrolment in higher education has gone up by \\ntwenty-eight per cent in ten years. \\nIn STEM courses, girls and women constitute forty-three \\nper cent of enrolment - one of the highest in the world.\\nEnhancement of Women‚Äôs dignity by\\nMaking ‚ÄòTriple Talaq‚Äô illegal\\nReservation of one-third seats for women in the Lok Sabha \\nand State legislative assemblies\\nGiving over 70% houses under PM Awas Yojana in rural \\nareas to women as sole or joint owners.\\nUnion Interim Budget 2024-25\\nYuva (Youth or Amrit Peedhi)\\nThe National Education Policy 2020 is ushering in transformational reforms.\\nPM ScHools for Rising India (PM SHRI) delivering quality teaching, and nurturing holistic and \\nwell-rounded individuals. \\nThe Skill India Mission: Trained 1.4 crore youth, upskilled and reskilled 54 lakh youth, and \\nestablished 3000 new ITIs. \\nNew institutions of higher learning: 7 IITs, 16 IIITs, 7 IIMs, 15 AIIMS and 390 universities have been \\nset up. \\nPM Mudra Yojana- Sanctioned 43 crore loans aggregating to 22.5 lakh crore.\\nFund of Funds, Start Up India, and Start Up Credit Guarantee schemes: Assisting youth and \\nmaking them ‚Äòrozgardata‚Äô. \\nYouth in Sports-\\nThe highest ever medal tally in Asian Games and Asian Para Games in 2023.\\nChess prodigy Praggnanandhaa put up a stiff fight against the reigning World Champion \\nMagnus Carlsson in 2023.\\nIndia has over 80 chess grandmasters compared to little over 20 in 2010.\\nAnnadata (Farmer)\\nPM-KISAN SAMMAN Yojana: Direct financial assistance is provided to \\n11.8 crore farmers, including marginal and small farmers.\\nPM Fasal Bima Yojana: Crop insurance is given to 4 crore farmers.\\nElectronic National Agriculture Market: Integrated 1361 mandis, and providing services to 1.8 \\ncrore farmers with trading volume of Rs 3 lakh crore.\\nOther measures like farmer-centric policies, income support, coverage of risks through price and \\ninsurance support, promotion of technologies and innovations through start-ups.\\n2017-18\\n23.3\\nPercent\\n2022-23\\n37.0\\nRise in Female Labour\\nForce Participation Rate'), Document(metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='Sustainable Development\\nCommitment to meet ‚ÄòNet Zero‚Äô by 2070\\nViability gap funding for wind energy\\nSetting up of coal gasification and liquefaction capacity\\nPhased mandatory blending of CNG, PNG and \\ncompressed biogas\\nFinancial assistance for procurement of biomass \\naggregation machinery\\nRooftop solarization-\\nUp to 300 units of free electricity per month for   1 \\ncrore households\\nAdoption of e-buses for public transport network\\nStrengthening e-vehicle ecosystem by supporting \\nmanufacturing and charging.\\nNew scheme of biomanufacturing and bio- foundry to be \\nlaunched to support environment friendly alternatives.\\nSTRATEGY FOR AMRIT KAAL\\nInfrastructure and Investment\\nImplementation of 3 major railway corridor programmes under PM Gati Shakti-to improve \\nlogistics efficiency and reduce cost.\\nPromotion of foreign investment via bilateral investment treaties to be negotiated.\\nExpansion of existing airports and comprehensive development of new airports under UDAN \\nscheme.\\nPromotion of urban transformation via Metro rail and NaMo Bharat.\\nAchievements till now\\n10 crore LPG  connections \\nreleased under PMUY\\n36.9 crore LED  bulbs, 72.2 lakh \\nLED  Tube lights\\n23.6 lakh  Energy efficient fans \\ndistributed under UJALA\\n1.3 crore  LED Street Lights \\ninstalled under SNLP\\nNon-Fossil Fuel installed energy \\ncapacity increased from 30.4% \\nin 2004 to 43.9% in 2023.\\nONLINE  |  DELHI  |  AHMEDABAD  |  BHOPAL  |  CHANDIGARH  |  GUWAHATI  |  HYDERABAD  |  JAIPUR  |  JODHPUR  |  LUCKNOW  |  PRAYAGRAJ  |  PUNE  |  RANCHI  |  SIKAR 6\\nIncrease in Capital Expenditure\\nAchievements till now\\nDoubling of FDI Inflow\\n0 0\\n1\\n2\\n3\\n4\\nUSD Billion\\nFY18 FY19 FY20 FY21 FY22 FY23 FY24\\n(BE) (BE)\\nFY25 2005-2014\\n298\\n596\\n2014-2023\\n3\\n6\\n9\\n12\\nUnion Interim Budget 2024-25'), Document(metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='Inclusive Development\\nAspirational Districts Programme to assist States in faster development and employment \\ngeneration.\\nDevelopment of the East To make the eastern region and its people a powerful driver of India‚Äôs \\ngrowth.\\nAdditional 2 crore houses targeted for next 5 years under PM Awas Yojana (Grameen) \\nHousing for middle class scheme to be launched to promote middle class to buy/built their \\nown houses.\\nMore medical colleges will be set up by utilizing the existing hospital infrastructure.\\nCervical Cancer Vaccination for girls in age group of 9 to 14 years.\\nMaternal and child health care- Various schemes to be brought under one comprehensive \\nprogramme for synergy in implementation.\\nUpgradation of anganwadi centres under ‚ÄúSaksham Anganwadi and Poshan 2.0‚Äù will be \\nexpedited for improved nutrition delivery, early childhood care and development.   \\nU-WIN platform will be rolled out for managing immunization and intensified efforts of Mission \\nIndradhanush.\\nExtension of Ayushman Bharat scheme to all ASHA workers, Anganwadi Workers and Helpers. \\nAgriculture and Food Processing\\nPromoting private and public investment in Post-harvest activities like aggregation, modern \\nstorage, efficient supply chains, primary and secondary processing and marketing and \\nbranding.\\nApplication of Nano DAP on various crops will be expanded in all agro-climatic zones.  \\nAtmanirbhar Oilseeds Abhiyaan-Strategy to be formulated to achieve atmanirbharta for \\noilseeds.\\nComprehensive programme for dairy development to be formulated to control foot and \\nmouth disease and increase productivity of milch aimals.\\nStepping up the implementation of Pradhan Mantri Matsaya Sampada Yojana to enhance \\naquaculture productivity, double exports and generate more employment opportunities \\n5 Integrated Aquaparks to be set up.\\nPromoting Blue Economy 2.0: a scheme for restoration and adaptation measures, and coastal \\naquaculture and mariculture with integrated and multi-sectoral approach will be launched\\nAchievements till now\\nInclusive Development\\nin Aspirational Districts (112)\\nPer cent\\n% of Women registered for \\nAnti-Natal Care within First \\nTrimester\\nNumber of enrolments under \\nPradhan Mantri Jeevan Jyoti \\nBima Yojana (PMJJBY) per lakh \\npopulation\\n2018\\n68\\n89\\nOct-23\\nNumber\\n2018\\n1737\\n13195\\nOct-23\\nIncreased allocation\\nfor PMAY\\n2023-24\\n(BE) (BE)\\n79590\\n80671\\n2024-25\\nCrore\\nONLINE  |  DELHI  |  AHMEDABAD  |  BHOPAL  |  CHANDIGARH  |  GUWAHATI  |  HYDERABAD  |  JAIPUR  |  JODHPUR  |  LUCKNOW  |  PRAYAGRAJ  |  PUNE  |  RANCHI  |  SIKAR 7\\nUnion Interim Budget 2024-25'), Document(metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='7\\nAchievements till now\\nRs. Crore\\nIncreased allocation for \\nBlue Revolution\\nIncreased allocation for PM- Formalisation of \\nMicro Food Processing Enterprises scheme\\n2023-24\\n(BE)\\n2025\\n2352\\n2024-25\\n(BE)\\nRs. Crore\\n2023-24\\n(BE)\\n639\\n880\\n2024-25\\n(BE)\\nUnion Interim Budget 2024-25\\nTourism\\nStates will be encouraged to take up comprehensive development of iconic tourist centres, branding \\nand marketing them at global scale.\\nA framework for rating of the centres based on quality of facilities and services will be \\nestablished.\\nLong-term interest free loans will be provided to States for financing such development on \\nmatching basis.\\nProjects for port connectivity, tourism infrastructure, and amenities will be taken up for islands, \\nincluding Lakshadweep.\\nONLINE  |  DELHI  |  AHMEDABAD  |  BHOPAL  |  CHANDIGARH  |  GUWAHATI  |  HYDERABAD  |  JAIPUR  |  JODHPUR  |  LUCKNOW  |  PRAYAGRAJ  |  PUNE  |  RANCHI  |  SIKAR 8\\nOther Measures\\nTo enhance the target for Lakhpati Didi from 2 crore to 3 crore. \\nLakhpati Didi refers to women members of Self Help Groups (SHGs) who earn a sustainable \\nincome of at least Rs 1 lakh per year per household. \\nPromoting Research and Innovation\\nA corpus of rupees one lakh crore will be established with fifty-year interest free loan. \\nA new scheme will be launched for strengthening deep-tech technologies for defence \\npurposes and expediting ‚Äòatmanirbharta‚Äô.\\nReforms in the States for ‚ÄòViksit Bharat‚Äô: A provision of seventy-five thousand crore rupees as \\nfifty-year interest free loan is proposed to support milestone-linked reforms by the State \\nGovernments.  \\nAddressing Societal Challenges: A high-powered committee will be formed to address \\nchallenges due to fast population growth and demographic changes and achieve the goal of \\n‚ÄòViksit Bharat‚Äô.'), Document(metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='Direct Tax\\nTax Collections more than trebled in \\nlast 10 years.\\nNumber of return filers swelled to 2.4 \\ntimes.\\nReduction in average processing time \\nof returns from 93 days in 2013-14 to \\n10 days in 2023-24.\\nNew Tax regime resulted in reduced \\nand rationalized tax rates\\nTaxpayers with income up to ‚Çπ7 lakh \\nhave no tax liability\\nThe threshold for presumptive \\ntaxation for retail businesses raised \\nfrom ‚Çπ2 crore to ‚Çπ3 crore.\\nCorporate tax rate decreased from \\n30% to 22% for existing companies \\nand 15% for new manufacturing \\ncompanies.\\nImprovement in tax-payer services \\nthrough\\nFaceless Assessment and Appeal\\nNew Form 26AS and prefilling of tax \\nreturns.\\nPART B\\nONLINE  |  DELHI  |  AHMEDABAD  |  BHOPAL  |  CHANDIGARH  |  GUWAHATI  |  HYDERABAD  |  JAIPUR  |  JODHPUR  |  LUCKNOW  |  PRAYAGRAJ  |  PUNE  |  RANCHI  |  SIKAR 9\\nDIRECT AND INDIRECT TAXES\\nGross Tax\\nReceips\\n11.2\\n5.1\\n2022-23\\n(Actuals)\\n2023-24\\n(Budget Estimates)\\n2023-24\\n(Revised Estimates)\\n2024-25\\n(Budget Estimates)\\n5.1 5.0 4.9\\n6.1 6.0\\n6.6 6.7\\n11.1 11.6 11.7\\nDirect Tax\\nIndirect Tax\\nOVERALL TREND IN TAX RECEIPTS:\\nIndirect Tax\\nAverage monthly Gross GST collections \\ndoubled to 21.66 lakh crore in FY24.\\nIncrease in tax buoyancy of State \\nrevenue from 0.72 (2012-16) to 1.22 in \\nthe post-GST period (2017-23)\\nReduction in logistics cost and prices of \\nmost goods and services\\nDecline in import release time since \\n2019\\n47 per cent at Inland Container \\nDepots\\n28 per cent at Air Cargo \\ncomplexes\\n27 per cent at Sea Ports\\nSupply Chain Optimization by \\neliminating tax arbitrage and octroi.\\nUnion Interim Budget 2024-25'), Document(metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content=\"Income\\nTax (19%)\\nBorrowing and\\nOther Liabilities\\n(28%)\\nUnion Excise\\nDuties (5%)\\nCorporation\\ntax (17%)\\nGST and other\\ntaxes (18%)\\nCustoms (4%)\\nPensions (4%)\\nNon-Tax\\nReceipts (7%)\\nNon-Debt Capital\\nReceipts (1%)\\nRUPEE COMES FROM RUPEE GOES TO\\nInterest \\nPayments\\n(20%)\\nOther\\nExpenditure\\n(9%)\\nStates' share\\nof Taxes\\nand Duties\\n(20%)\\nCentrally\\nSponsored\\nSchemes\\n(8%)\\nSubsidies\\n(6%)Central Sector\\nSchemes\\n(16%)\\nFinance\\nCommission\\nand other \\ntransfers\\n(8%)\\nDefence (8%)\\nTAX PROPOSALS\\nContinuity in taxation: Certain tax benefits to Start-ups and investments made by sovereign \\nwealth funds/pension funds and tax exemption of some IFSC units extended up to 31.03.2025.\\nWithdrawal of outstanding direct tax demand: -\\nUp to ‚Çπ25,000 pertaining up to FY10\\nUp to ‚Çπ10,000 for FY11-FY15\\nThis is expected to benefit approx. 1 crore taxpayers\\nRetention of same tax rates for direct and indirect taxes, import duties, corporate taxes.\\nONLINE  |  DELHI  |  AHMEDABAD  |  BHOPAL  |  CHANDIGARH  |  GUWAHATI  |  HYDERABAD  |  JAIPUR  |  JODHPUR  |  LUCKNOW  |  PRAYAGRAJ  |  PUNE  |  RANCHI  |  SIKAR 10\\n2022-23\\n(Actuals)\\n2023-24\\n(Budget Estimates)\\n2023-24\\n(Revised Estimates)\\n2024-25\\n(Budget Estimates)\\n0\\n1,00,000\\n10,00,000\\n11,00,000\\n12,00,000\\n-1,00,000\\n2,00,000\\n3,00,000\\n4,00,000\\n5,00,000\\nSources of Financing FD\\n(Excluding Market Borrowings)\\nMarket Borrowings\\nMarket Borrowings\\nSources of DeÔ¨Åcit Financing\\nShort Term\\nBorrowing\\nSecurities Against\\nSmall Savings\\nState\\nProvident Funds\\nOther Receipts\\n(Internal Debt and Public Account) External Debt Draw Down of\\nCash Balance\\nIn   crore\\nUnion Interim Budget 2024-25\"), Document(metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='ONLINE  |  DELHI  |  AHMEDABAD  |  BHOPAL  |  CHANDIGARH  |  GUWAHATI  |  HYDERABAD  |  JAIPUR  |  JODHPUR  |  LUCKNOW  |  PRAYAGRAJ  |  PUNE  |  RANCHI  |  SIKAR 11\\n0.0\\n0.5\\n1.0\\n1.5\\n2.0\\n2.5\\nFY14\\nFY15\\nFY16\\nFY17\\nFY18\\nFY19\\nFY20\\nFY21\\nFY22\\nFY23\\nH1: FY24\\nPDG fo tnec reP\\nDeclining CAD as % of GDP\\n6.1 5.8\\n4.8\\n4.2 4.1\\n3.2\\n2017-18 2018-19 2019-20 2020-21 2021-22 2022-23\\nPer cent\\nDeclining Unemployment Rate \\n3.8 4.3\\n7.5\\n9.3\\n11.2\\n9.1\\n8.2\\n7.3\\n5.8\\n3.2\\nFY14\\nFY15\\nFY16\\nFY17\\nFY18\\nFY19\\nFY20\\nFY21\\nFY22\\nSep-23\\nsecnavdA ssorG fo % a sAPN ssorG\\nDeclining GNPAs as % of \\nGross Advances \\n0\\n4000\\n8000\\n12000\\n16000\\nFY18 FY19 FY20 FY21 FY22 FY23 FY24\\nCrore\\nRising volume of Digital \\nTransactions\\n0.9\\n1.0 1.0\\n0.9\\n1.2\\n1.5\\n1.7\\n0.6\\n0.9\\n1.2\\n1.5\\n1.8\\nFY18\\nFY19\\nFY20\\nFY21\\nFY22\\nFY23\\nFY24\\nerorC hkaL ‚Çπ\\nRise in average monthly gross \\nGST collections\\n9.4\\n5.8\\n4.9 4.5\\n3.6 3.4\\n4.8\\n6.2\\n5.5\\n6.7\\n5.5\\nFY14\\nFY15\\nFY16\\nFY17\\nFY18\\nFY19\\nFY20\\nFY21\\nFY22\\nFY23\\nFY24*\\nPer cent\\nFall in Headline Inflation\\nPERFORMANCE OF INDIAN ECONOMY\\nUnion Interim Budget 2024-25'), Document(metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content=\"ONLINE  |  DELHI  |  AHMEDABAD  |  BHOPAL  |  CHANDIGARH  |  GUWAHATI  |  HYDERABAD  |  JAIPUR  |  JODHPUR  |  LUCKNOW  |  PRAYAGRAJ  |  PUNE  |  RANCHI  |  SIKAR 12\\nAppropriation\\nBill\\nIt gives power to the government to withdraw funds from the Consolidated \\nFund of India for meeting the expenditure during the financial year. \\nOctroi It is tax levied by a local municipal authority, on certain categories of \\ngoods as they enter the area.\\nSovereign\\nWealth Funds\\nThey are state-owned investment pool that manages a country's financial \\nreserves, investing in various assets such as stocks, bonds, real estate, and \\nother instruments to generate long-term wealth and achieve economic \\nobjectives.\\nCustom Duty It is a tax imposed on imports and exports of goods.\\nTax arbitrage It is strategically exploiting differences in tax regulations or rates between \\njurisdictions to minimise tax liability or maximise financial gains.\\nDirect taxes Tax payments made directly to the government by individuals, including \\nincome tax, poll tax, land tax, and personal property tax.\\nIndirect Taxes\\nTaxes imposed on goods and services, collected by intermediaries such as \\nmanufacturers or retailers who pass it on to the final consumer. Examples \\ninclude Goods and Services Tax (GST), excise duty, and customs duty.\\nUnion Interim Budget 2024-25\\nRevenue\\nreceipts\\nIt refers to the money the government receives without incurring debts or \\nlosing valuable assets, covering items like taxes, profits from public enter-\\nprises, and fees for services.\\nCorporate tax\\nIt is a direct tax imposed by governments on a company's profits, \\ncalculated as a percentage of its net income, to generate revenue for public \\nservices and infrastructure.\\nTax buoyancy\\nIt measures how tax revenues respond to changes in economic output, \\nreflecting an economy's attributes, effective collections, and the impact of \\npolicy measures over time.\\nViability gap\\nfunding\\nIt provides grants to back economically justified yet financially nonviable \\nprojects.\\nPresumptive\\ntaxation\\nIt is a simplified method allowing eligible businesses to declare a pre-\\nscribed percentage of turnover as income, streamlining tax compliance by \\nminimising the need for detailed accounting records.\\nInflation It is the rate of increase in prices over or how much more expensive a set of \\ngoods and services has become over a given time period.\\nCapital\\nexpenditure\\nIt is the government's investment in long-term development, including \\nmachinery, buildings, and education, as well as acquiring assets like land \\nand profitable investments for future returns.\\nBudget\\nestimates\\nThey are financial projections presented by the Union finance minister, \\noutlining allocations for different sectors in the annual budget. They signify \\nthe government's intended expenditure but are not exact figures or binding \\ncommitment.\\nDirect\\nBenefit\\nTransfer\\nThe aim of DBT is to transfer the benefits and subsidies of various social \\nwelfare schemes directly in the bank account of the beneficiary on time. \\nThis eliminates the intermediary body, prevent any frauds and brings effi-\\nciency, effectiveness and transparency.\\nLabour Force\\nParticipation\\nrate\\nIt is a measure of the proportion of a country's working-age population \\nthat engages actively in the labour market, either by working or looking for \\nwork.\\nGLOSSARY\"), Document(metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 12, 'page_label': '13'}, page_content='IMPORTANT CONSTITUTIONAL PROVISIONS RELATED TO BUDGET\\nARTICLE PROVISION\\nArticle 109 Special procedure in respect of Money Bills\\nArticle 110 Definition of Money Bills\\nArticle 112 Annual Financial Statement\\nArticle 113 Procedure in Parliament with respect to Estimates.\\nArticle 114 Appropriation Bills\\nArticle 115 Supplementary, Additional or Excess Grants.\\nArticle 116 Vote on account, Vote of credit and Exceptional Grant\\nArticle 117 Special provisions as to Financial Bills\\nArticle 150 Form of accounts of the Union and of the States\\nArticle 151 Audit reports\\nArticle 265 Taxes not to be imposed except by authority of law\\nConsolidated Funds and Public Accounts of India and of the StatesArticle 266\\nContingency FundArticle 267\\nGrants from the Union to certain StatesArticle 275\\nFinance CommissionArticle 280\\nRecommendations of the Finance CommissionArticle 281\\nBorrowing by the Government of IndiaArticle 292\\nUnion Interim Budget 2024-25')]\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# pdf loader \n",
    "# LangChain document loaders implement lazy_load and its async variant, alazy_load,\n",
    "# which return iterators of Document objects. We will use these below.\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "file_path = \"./data/sample.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)\n",
    "\n",
    "print(pages)\n",
    "print(len(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.8)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.42 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-openai) (0.3.45)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-openai) (1.66.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.42->langchain-openai) (0.3.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.42->langchain-openai) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.42->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.42->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.42->langchain-openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.42->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.42->langchain-openai) (2.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.42->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain-openai) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.42->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.42->langchain-openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.58.1->langchain-openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# vector search over PDFs\n",
    "! pip install langchain-openai\n",
    "\n",
    "import os, getpass\n",
    "def set_env(key: str,env_var_name: str):\n",
    "    os.environ[env_var_name] = key\n",
    "\n",
    "api_key = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "set_env(api_key, \"OPENAI_API_KEY\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 3: Vision of Budget: Viksit Bharat by 2047 ‚ÄúProsperous \n",
      "Bharat in harmony with nature, modern infrastructure \n",
      "and opportunities for all‚Äù\n",
      "Development Mantra of Budget: Sabka Saath, Sabka \n",
      "Vikas, and Sabka Vishwas‚Äô whole of nation‚Äô approach of \n",
      "‚ÄòSabka Prayas‚Äô.\n",
      "Philosophy is to cover all elements of inclu\n",
      "\n",
      "Page 7: 7\n",
      "Achievements till now\n",
      "Rs. Crore\n",
      "Increased allocation for \n",
      "Blue Revolution\n",
      "Increased allocation for PM- Formalisation of \n",
      "Micro Food Processing Enterprises scheme\n",
      "2023-24\n",
      "(BE)\n",
      "2025\n",
      "2352\n",
      "2024-25\n",
      "(BE)\n",
      "Rs. Crore\n",
      "2023-24\n",
      "(BE)\n",
      "639\n",
      "880\n",
      "2024-25\n",
      "(BE)\n",
      "Union Interim Budget 2024-25\n",
      "Tourism\n",
      "States will be enco\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vector_store = InMemoryVectorStore.from_documents(pages, OpenAIEmbeddings())\n",
    "docs = vector_store.similarity_search(\"what is approach of Sabka Prayas\", k=2)\n",
    "for doc in docs:\n",
    "    print(f'Page {doc.metadata[\"page\"]}: {doc.page_content[:300]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Category: Demand No. 1\n",
      "Sl.No.: 1\n",
      "Ministry/Department: Department of Agriculture and Farmers Welfare\n",
      "Scheme: Crop Insurance Scheme\n",
      "Actuals 2021-2022 Revenue: 13549.24\n",
      "Actuals 2021-2022 Capital: 0\n",
      "Actuals 2021-2022 Total: 13549.24\n",
      "Budget Estimates 2022-2023 Revenue: 15500\n",
      "Budget Estimates 2022-2023 Capital: 0\n",
      "Budget Estimates 2022-2023 Total: 15500\n",
      "Revised Estimates2022-2023 Revenue: 12375.76\n",
      "Revised Estimates 2022-2023 Revenue: 0\n",
      "Revised Estimates2022-2023 Total: 12375.76\n",
      "Budget Estimates2023-2024 Revenue: 13625\n",
      "Budget Estimates2023-2024 Capital: 0\n",
      "Budget Estimates2023-2024 Total: 13625' metadata={'source': './data/sample.csv', 'row': 0}\n",
      "page_content='Category: Demand No. 1\n",
      "Sl.No.: 2\n",
      "Ministry/Department: Department of Agriculture and Farmers Welfare\n",
      "Scheme: Interest Subsidy for Short Term Credit to Farmers\n",
      "Actuals 2021-2022 Revenue: 21476.93\n",
      "Actuals 2021-2022 Capital: 0\n",
      "Actuals 2021-2022 Total: 21476.93\n",
      "Budget Estimates 2022-2023 Revenue: 0\n",
      "Budget Estimates 2022-2023 Capital: 0\n",
      "Budget Estimates 2022-2023 Total: 0\n",
      "Revised Estimates2022-2023 Revenue: 0\n",
      "Revised Estimates 2022-2023 Revenue: 0\n",
      "Revised Estimates2022-2023 Total: 0\n",
      "Budget Estimates2023-2024 Revenue: 0\n",
      "Budget Estimates2023-2024 Capital: 0\n",
      "Budget Estimates2023-2024 Total: 0' metadata={'source': './data/sample.csv', 'row': 1}\n"
     ]
    }
   ],
   "source": [
    "# csv loader \n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "file_path = \"./data/sample.csv\"\n",
    "\n",
    "loader = CSVLoader(file_path=file_path)\n",
    "data = loader.load()\n",
    "\n",
    "for record in data[:2]: \n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': \"Just saw a LinkedIn Influencer with 'Organic Growth' written in the profile with 65K+ followers claiming that he can help you in growing your platform, copying the posts from other influencers.\", 'engagement': 90, 'line_count': 3, 'language': 'English', 'tags': ['Influencer', 'Personal Growth'], 'tone': 'Professional'}, {'text': \"Jobseekers, this one‚Äôs for you.\\n Every application, every interview, every follow-up‚Ä¶ the pressure is immense.\\n And I know what you're thinking: Am I not good enough? \\n But let me tell you, this isn‚Äôt about you or your skills. It‚Äôs about a broken system where 60% of applicants never hear back. \\n Your mental health is not worth sacrificing for a system that doesn‚Äôt acknowledge your worth. \\n Please remember, taking care of yourself is the real priority. \\n Your dream job will come, but for now, breathe. üåª\", 'engagement': 347, 'line_count': 8, 'language': 'English', 'tags': ['Mental Health', 'Job Search'], 'tone': 'Inspirational'}, {'text': 'Looking for jobs on LinkedIn is like online dating: Full of promises, but in the end, you‚Äôre just left ghosted.', 'engagement': 109, 'line_count': 1, 'language': 'English', 'tags': ['Online Dating', 'Job Search'], 'tone': 'Humorous'}, {'text': \"LinkedIn scams be like: 'Congratulations, you've been selected for a role you didn‚Äôt even apply for!' \\n The catch? Pay Rs. 50,000 for the honor.\", 'engagement': 115, 'line_count': 3, 'language': 'English', 'tags': ['Scams', 'LinkedIn'], 'tone': 'Humorous'}, {'text': \"sapne dekhna achi baat hai,\\nlekin job ka sapna dekh ke 'interested' likhna,\\nyeh toh achi baat nahi hai na?\", 'engagement': 545, 'line_count': 3, 'language': 'Hindi', 'tags': ['Career Development', 'Job Search'], 'tone': 'Humorous'}, {'text': \"Next time when I'll be reading some LinkedIn Influencer's story, I am starting from the last line.\\nIf there's a link attached to it, it's most probably a fake one.\\nSaves me time!\", 'engagement': 188, 'line_count': 3, 'language': 'English', 'tags': ['Productivity', 'Time Management'], 'tone': 'Casual'}, {'text': \"Every time I poured my heart into 5-6 rounds of interviews and faced rejection, it felt like a punch in the gut. The sleepless nights, the endless preparation, all for nothing.\\n\\nBut looking back, I realize it wasn‚Äôt nothing. It was the Universe‚Äôs way of saying, ‚ÄúNot this one, something better is on the way.‚Äù\\n\\nEvery single time, I‚Äôve been shown why that rejection happened.\\n\\nDoors I thought I wanted to walk through were shut, only to have the right ones swing open.\\n\\nThe kind that aligned with my growth, my values, and my happiness.\\n\\nAt first, it stung. It hurt deeply. But now, when things don‚Äôt go as planned, I don‚Äôt panic.\\n\\nI don‚Äôt question my worth. I sit back, breathe, and trust. The Universe knows.\\n\\nI know there's another plan waiting. Something bigger, better, and just for me.\\n\\nTo anyone feeling the weight of rejection: trust that the closed doors are protecting you from something you can‚Äôt see right now.\\n\\nYour path is being cleared for something even more beautiful.\", 'engagement': 206, 'line_count': 11, 'language': 'English', 'tags': ['Motivation', 'Job Search'], 'tone': 'Inspirational'}, {'text': \"To everyone who's still looking for a job...\\n\\nI see you. I feel you. üíî\\n\\nEvery rejection email feels like a punch in the gut, and every 'We'll get back to you' sounds more like 'You'll never hear from us.'\\n\\nBut I want you to know, you're not alone in this. üå∏\\n\\nAccording to a study, 80% of jobseekers struggle with anxiety and self-doubt during their search. It's normal to feel lost, but it's not the end.\\n\\nTake breaks, breathe, and remember, this doesn't define you. Your worth is not tied to an offer letter. üí•\\n\\nYour mental health matters more than any job.\", 'engagement': 899, 'line_count': 9, 'language': 'English', 'tags': ['Mental Health', 'Job Search'], 'tone': 'Inspirational'}, {'text': \"Sometimes, we forget that a company‚Äôs brand name doesn‚Äôt define someone‚Äôs talent. It‚Äôs easy to get caught up in the 'big company = big talent' mindset, but that's not always the case.\\n\\nI‚Äôve had the privilege of working with people from smaller companies (lesser known) who blow me away with their skills and dedication. They don‚Äôt need a fancy title or a famous brand behind them to prove their worth.\\n\\nI've seen the other side too‚Äîpeople in top-tier companies feeling lost, overwhelmed, or stuck, even though the world sees them as 'successful'.\\n\\nLet‚Äôs stop attaching someone‚Äôs value to the company they work for. Freshers especially need to hear this‚Äîskills are what matter, not the size of the company behind them.\\n\\nAt the end of the day, happiness and growth don‚Äôt come from a brand name, they come from doing what you love and constantly improving your craft.\", 'engagement': 166, 'line_count': 11, 'language': 'English', 'tags': ['Career Advice', 'Personal Growth'], 'tone': 'Inspirational'}, {'text': \"So when I left a toxic work environment, I told my manager a simple thing and felt so good üòØ\\n\\nI just said-\\n\\n'Hope your son gets a manager like you.\\nI hope that the manager behaves the same way as you did with me.\\nThank you.'\\n\\nNow tell me 1 thing-\\n\\nShe always said that she was a great manager.\\nWhy will she get offended?\\n\\nI just told her that I wish her son would get a manager like she was.\\n\\nIf you felt bad, then that means you were a bad manager and now you know it. \\ud83e\\x0880\\n\\nIf you feel good, then take it as a blessing for your son and you'll really want someone to treat your son/daughter in the same way.\\n\\nShe cannot be even angry with me else it'll prove that she was not a 'great' manager.\\n\\nMuskan - 1\\nManager - 0\\n\\nMuskan -> Aura +100000000\\n\\n(Fictional message unfortunately :(\\n)\\n\\nHope you all become the people that your sons/daughters will like to work under üôè\\n\\nThere are a lot of bad people/things, bring a small change and break the chain :)\", 'engagement': 1111, 'line_count': 13, 'language': 'English', 'tags': ['Professional', 'Humor'], 'tone': 'Humorous'}, {'text': \"I am an AI Tools & ChatGPT Expert, and my salary package is 42 LPA.\\n\\nSounds familiar? If you‚Äôve been on YouTube recently, I‚Äôm sure you‚Äôve seen this ad at least 100 times. Now, I have just one simple question ‚Äì Can someone please tell me which companies are hiring for this role and paying 42 LPA? Because I‚Äôm also considering a career switch! üòÇ\\n\\nSee guys, learning how to use a few AI tools won't magically get you a 42 LPA job. Selling courses isn‚Äôt wrong, but selling them by giving false hopes is. Just because someone tells you that learning how to use a few AI tools will instantly land you a high-paying job doesn‚Äôt make it true.\\n\\nSo, a humble request ‚Äì don‚Äôt fall for these unrealistic promises. Invest in courses only to upskill yourself, not with the expectation of overnight success.\\nIf anyone actually finds this 42 LPA AI Tools & ChatGPT Expert job, please let me know. I‚Äôll also update my resume! ü§£\", 'engagement': 319, 'line_count': 9, 'language': 'English', 'tags': ['Career Development', 'AI Tools'], 'tone': 'Professional'}, {'text': \"People talk about writing on LinkedIn like it‚Äôs a formula.\\n\\nWrite about this + this.\\n\\nAnd your posts will do well.\\n\\nBut what does 'well' even mean?\\n\\nLots of likes?\\nLots of reach?\\nLots of people seeing your post?\\n\\nThey don‚Äôt talk about the type of people liking it.\\nThe kind of reach you‚Äôre getting.\\nThe exact people seeing your post.\\n\\nThere‚Äôs a lot you can't control.\\nBut there are things you can.\\n\\nDefining what 'well' means for yourself is one of them.\\n\\nBecause someone else‚Äôs 'well' is not your 'well.'\\n\\nIf you‚Äôre blindly following, you don‚Äôt have an algorithm issue.\\n\\nYou have a strategy issue.\\n\\nBecause your strategy informs what you do.\\n\\nAnd just as importantly, what you don‚Äôt do.\\n\\nYour strategy will inform your positioning.\\n\\nThat in turn will shape your messaging.\\n\\nAnd your messaging connects with....\\n\\nWell‚Ä¶\\n\\nYour customers.\\n\\nNot just well. But really well.\\n\\n---\\n\\nControl the things you can and should.\", 'engagement': 200, 'line_count': 15, 'language': 'English', 'tags': ['Algorithm', 'Strategy'], 'tone': 'Professional'}, {'text': \"3 things a vacation with my parents taught me.\\n\\n(This was the first time when just the 3 of us had gone for a holiday.\\nIt turned out to be an awesome experience - much better than I had thought.)\\n\\nUpon my return, the next day as I was meditating, I reflected on the 4 days, asking myself if there was anything new I figured about myself or them.\\n\\nHere they are:\\n\\n1. No amount of material success, social validation, professional growth or bank balance can match up to the feeling of pampering your parents and making them feel proud of who you have become.\\n\\nTheir pride when people asked me for selfies, the comfort in which we travelled and stayed - everything made them act like kids in a toy store.\\n\\nNothing makes a child happier than to see their parents experience this joy.\\n\\n2. The number of such occasions with your parents is drastically reducing.\\n\\nWe walked for 5-8kms every day and by the end of the day, both of them were quite tired. They are both 70+, so it's a matter of a few years until such holidays come to a stop.\\n\\nI wish I had started long ago :(\\n\\n3. Your parents have lived their life and are set in their ways.\\nWhat they need now is not change.\\nWhat they need is acceptance.\\n\\nI do not agree with everything that my parents say or do, and for the longest time, I thought it is my duty to change their ways.\\n\\nI was wrong.\\n\\nAt this age, the best I can do is to accept them.\\n\\nThere isn't much time.\\n\\nCall them, visit them, spend time with them, travel with them.\\n\\nThey do not need your money.\\nThey need your time.\\n\\nPS: Every week, I share such thoughts in my newsletter. You can receive that email for free by subscribing from the link in comments.\", 'engagement': 2454, 'line_count': 23, 'language': 'English', 'tags': ['Family'], 'tone': 'Inspirational'}, {'text': \"If you don't understand the value of retention you can't survive the Service industry.\\n\\nBut, why do people promote retention of clients?\\n\\nBecause it's proof of the quality of services you are providing.\\n\\nI retained 50% of my clients to date.\\n\\nWhenever I ask them about their expectations,\\n\\nThey end up saying 'We don't have to worry about this, we know the quality you offer.'\\n\\nHow do you retain clients?\\n\\nONE Formula\\n\\n- never compromise with the quality you offer\\n\\nClients return for the experience.\\n\\nAs we say Experience>>>>>>>>>>\\n\\nBy creating content that resonates, I help B2B and B2C retain their customers.\", 'engagement': 16, 'line_count': 9, 'language': 'English', 'tags': ['Retention', 'Service', 'Quality', 'Business'], 'tone': 'Professional'}, {'text': \"I landed my dream tech job in the USA during a recession... without sending a single application!\\n\\nYep, you read that right. And no, it wasn't just luck.\\n\\nHere‚Äôs how I made it happen:\\n\\nI went all-in on making my LinkedIn profile stand out.\\n\\nEvery project I worked on? Posted it.\\n\\nThe impact it had? Documented it.\\n\\nThe problems it solved? Broke it all down.\\n\\nThen I discovered my golden ticket - Kaggle competitions.\\n\\nInstead of just participating, I started publishing in-depth notebooks breaking down complex ML problems into bite-sized pieces.\\n\\nEach notebook told a story: the 'why' behind feature engineering, the reasoning for model selection, even the failed experiments.\\n\\nI was solving real problems and teaching others along the way.\\n\\nBefore I knew it, people were actually engaging with my content, and guess who started sliding into my DMs? Hiring managers!\", 'engagement': 1400, 'line_count': 11, 'language': 'English', 'tags': ['LinkedIn', 'Job Search'], 'tone': 'Professional'}, {'text': \"Remote work is not just a trend; it's becoming the future of work. Many companies are adopting flexible working models, but challenges remain in maintaining productivity and collaboration. How do you ensure work-life balance while working remotely?\", 'engagement': 421, 'line_count': 3, 'language': 'English', 'tags': ['Productivity', 'Remote Work'], 'tone': 'Neutral'}, {'text': '‰∫∫Â∑•Êô∫ËÉΩÊ≠£Âú®È¢†Ë¶ÜÂêÑË°åÂêÑ‰∏öÔºå‰ªéÂåªÁñó‰øùÂÅ•Âà∞ÈáëËûçÔºåÂÜçÂà∞ÊïôËÇ≤„ÄÇËôΩÁÑ∂ÂÆÉÂ∏¶Êù•‰∫ÜÂ∑®Â§ßÁöÑ‰æøÂà©ÂíåÊïàÁéáÔºå‰ΩÜ‰πüÂºïÂèë‰∫ÜÂÖ≥‰∫éÈöêÁßÅÂíåÂ∞±‰∏öÁöÑÊãÖÂøß„ÄÇ‰Ω†ËÆ§‰∏∫‰∫∫Â∑•Êô∫ËÉΩ‰ºöÂ¶Ç‰ΩïÂΩ±ÂìçÊú™Êù•ÁöÑÂ∑•‰ΩúÂ∏ÇÂú∫Ôºü', 'engagement': 387, 'line_count': 3, 'language': 'Mandarin', 'tags': ['Artificial Intelligence', 'Job Search'], 'tone': 'Neutral'}, {'text': '‡§ò‡§∞ ‡§∏‡•á ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§π‡•ã‡§®‡•á ‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§∞‡•ç‡§Æ‡§ö‡§æ‡§∞‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§ï‡§§‡§æ ‡§¨‡§¢‡§º‡§§‡•Ä ‡§π‡•à ‡§Ø‡§æ ‡§ò‡§ü‡§§‡•Ä ‡§π‡•à? ‡§ï‡•Å‡§õ ‡§≤‡•ã‡§ó ‡§á‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§≤‡§ö‡•Ä‡§≤‡§æ‡§™‡§® ‡§¶‡•á‡§®‡•á ‡§µ‡§æ‡§≤‡§æ ‡§Æ‡§æ‡§®‡§§‡•á ‡§π‡•à‡§Ç, ‡§ú‡§¨‡§ï‡§ø ‡§ï‡•Å‡§õ ‡§ï‡§æ ‡§Æ‡§æ‡§®‡§®‡§æ ‡§π‡•à ‡§ï‡§ø ‡§á‡§∏‡§∏‡•á ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§≠‡§ü‡§ï ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§ ‡§Ü‡§™‡§ï‡§æ ‡§ï‡•ç‡§Ø‡§æ ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§π‡•à?', 'engagement': 532, 'line_count': 4, 'language': 'Hindi', 'tags': ['Productivity', 'Employee'], 'tone': 'Neutral'}, {'text': 'La transformaci√≥n digital ha cambiado la forma en que operan las empresas. Desde la automatizaci√≥n de procesos hasta la integraci√≥n de inteligencia artificial, cada sector est√° evolucionando. ¬øCrees que las empresas deben priorizar la digitalizaci√≥n para seguir siendo competitivas?', 'engagement': 289, 'line_count': 3, 'language': 'Spanish', 'tags': ['Digitalization', 'Competitive'], 'tone': 'Professional'}, {'text': \"L'innovation technologique joue un r√¥le cl√© dans le d√©veloppement durable. L'intelligence artificielle et les √©nergies renouvelables offrent des solutions prometteuses. Comment pouvons-nous √©quilibrer innovation et protection de l'environnement?\", 'engagement': 415, 'line_count': 3, 'language': 'French', 'tags': ['Durable', 'Innovation'], 'tone': 'Professional'}, {'text': 'ÿßŸÑÿ¥ŸÖŸàŸÑŸäÿ© ŸÅŸä ÿ®Ÿäÿ¶ÿ© ÿßŸÑÿπŸÖŸÑ ÿßŸÑÿ≠ÿØŸäÿ´ÿ© ÿ£ÿµÿ®ÿ≠ÿ™ ŸÖŸÜ ÿ£ŸáŸÖ ÿßŸÑŸÖŸàÿßÿ∂Ÿäÿπ ÿßŸÑÿ™Ÿä ÿ™ŸÜÿßŸÇÿ¥Ÿáÿß ÿßŸÑÿ¥ÿ±ŸÉÿßÿ™ ÿßŸÑŸäŸàŸÖ. ŸÖŸÜ ÿ∂ŸÖÿßŸÜ ÿßŸÑÿ™ŸÜŸàÿπ ÿßŸÑÿ´ŸÇÿßŸÅŸä ÿ•ŸÑŸâ ÿ™ŸàŸÅŸäÿ± ŸÅÿ±ÿµ ŸÖÿ™ŸÉÿßŸÅÿ¶ÿ©ÿå ŸÖÿß ŸáŸä ÿ®ÿ±ÿ£ŸäŸÉ ÿ£ŸÅÿ∂ŸÑ ÿßŸÑÿ∑ÿ±ŸÇ ŸÑÿ¨ÿπŸÑ ÿ®Ÿäÿ¶ÿ© ÿßŸÑÿπŸÖŸÑ ÿ£ŸÉÿ´ÿ± ÿ¥ŸÖŸàŸÑŸäÿ© Ÿàÿ•ŸÜÿµÿßŸÅŸãÿßÿü', 'engagement': 368, 'line_count': 3, 'language': 'Arabic', 'tags': ['Work Environment', 'Diversity'], 'tone': 'Neutral'}, {'text': '‡¶¨‡ßà‡¶ö‡¶ø‡¶§‡ßç‡¶∞‡ßç‡¶Ø ‡¶è‡¶¨‡¶Ç ‡¶Ö‡¶®‡ßç‡¶§‡¶∞‡ßç‡¶≠‡ßÅ‡¶ï‡ßç‡¶§‡¶ø ‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶ï‡¶∞‡ßç‡¶™‡ßã‡¶∞‡ßá‡¶ü ‡¶¶‡ßÅ‡¶®‡¶ø‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø‡¶á ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶®‡¶Ø‡¶º, ‡¶è‡¶ü‡¶ø ‡¶∏‡¶Æ‡¶æ‡¶ú‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø‡¶ì ‡¶Ö‡¶™‡¶∞‡¶ø‡¶π‡¶æ‡¶∞‡ßç‡¶Ø‡•§ ‡¶ï‡¶∞‡ßç‡¶Æ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡¶∞‡ßá ‡¶≤‡¶ø‡¶ô‡ßç‡¶ó ‡¶∏‡¶Æ‡¶§‡¶æ, ‡¶∏‡¶æ‡¶Ç‡¶∏‡ßç‡¶ï‡ßÉ‡¶§‡¶ø‡¶ï ‡¶¨‡ßà‡¶ö‡¶ø‡¶§‡ßç‡¶∞‡ßç‡¶Ø ‡¶è‡¶¨‡¶Ç ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶¨‡¶®‡ßç‡¶ß‡ßÄ‡¶¶‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶∏‡ßÅ‡¶Ø‡ßã‡¶ó ‡¶∏‡ßÉ‡¶∑‡ßç‡¶ü‡¶ø‡¶∞ ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡ßÄ ‡¶Æ‡¶§‡¶æ‡¶Æ‡¶§?', 'engagement': 272, 'line_count': 5, 'language': 'Hindi', 'tags': ['Diversity', 'Corporate World'], 'tone': 'Professional'}, {'text': 'A sustentabilidade √© uma prioridade para muitas empresas hoje em dia. Desde a redu√ß√£o da pegada de carbono at√© a ado√ß√£o de pr√°ticas mais ecol√≥gicas, h√° muito a ser feito. Como sua empresa est√° contribuindo para um futuro mais sustent√°vel?', 'engagement': 329, 'line_count': 3, 'language': 'Portuguese', 'tags': ['Sustainability'], 'tone': 'Neutral'}, {'text': '–õ–∏–¥–µ—Ä—Å—Ç–≤–æ –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º –º–∏—Ä–µ —Ç—Ä–µ–±—É–µ—Ç —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –∏ –≥–∏–±–∫–æ—Å—Ç–∏. –ö—Ä–∏–∑–∏—Å—ã –∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å —Å—Ç–∞–ª–∏ –Ω–æ—Ä–º–æ–π. –ö–∞–∫ –ª–∏–¥–µ—Ä—ã –º–æ–≥—É—Ç —Ä–∞–∑–≤–∏–≤–∞—Ç—å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∏ –≤–¥–æ—Ö–Ω–æ–≤–ª—è—Ç—å —Å–≤–æ–∏ –∫–æ–º–∞–Ω–¥—ã?', 'engagement': 451, 'line_count': 3, 'language': 'Russian', 'tags': ['Leadership', 'Resilience'], 'tone': 'Professional'}, {'text': 'ÿßŸÑÿπŸÖŸÑ ÿπŸÜ ÿ®ÿπÿØ ÿ£ÿµÿ®ÿ≠ ÿ≠ŸÇŸäŸÇÿ© ŸÑÿß ŸÖŸÅÿ± ŸÖŸÜŸáÿß. ŸàŸÑŸÉŸÜ ŸÉŸäŸÅ ŸÜÿ≠ÿßŸÅÿ∏ ÿπŸÑŸâ ÿßŸÑÿ™ÿ≠ŸÅŸäÿ≤ ŸàÿßŸÑÿ™ŸÅÿßÿπŸÑ ÿ®ŸäŸÜ ÿßŸÑÿ≤ŸÖŸÑÿßÿ° ÿπŸÜÿØŸÖÿß ŸÜÿπŸÖŸÑ ŸÖŸÜ ŸÖŸÜÿßÿ≤ŸÑŸÜÿßÿü ŸáŸÑ ÿ™ÿπÿ™ŸÇÿØ ÿ£ŸÜ ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπÿßÿ™ ÿßŸÑÿßŸÅÿ™ÿ±ÿßÿ∂Ÿäÿ© ŸÅÿπÿßŸÑÿ© ÿ®ŸÇÿØÿ± ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπÿßÿ™ ÿßŸÑÿ™ŸÇŸÑŸäÿØŸäÿ©ÿü', 'engagement': 390, 'line_count': 3, 'language': 'Arabic', 'tags': ['Virtual Meetings', 'Remote Work'], 'tone': 'Professional'}, {'text': 'Hinglish: Sustainability kaafi important hai! Par kya hum apni daily life mein eco-friendly practices ko adopt kar rahe hain? Aap kya kar rahe hain pollution aur waste reduction ke liye?', 'engagement': 498, 'line_count': 3, 'language': 'Hindi', 'tags': ['Eco-Friendly', 'Sustainability'], 'tone': 'Neutral'}, {'text': 'AI is transforming healthcare at an unprecedented pace. From AI-driven diagnostics to robotic surgeries, technology is improving patient outcomes. However, concerns about data privacy and ethical implications remain. How do you think AI will shape the future of healthcare?', 'engagement': 379, 'line_count': 4, 'language': 'English', 'tags': ['Artificial Intelligence', 'Healthcare'], 'tone': 'Neutral'}, {'text': '‰∫∫Â∑•Êô∫ÊÖßÊäÄË°ìÊ≠£Âú®ÈÄ≤‰∏ÄÊ≠•ÊîπÂñÑÁí∞Â¢É‰øùË≠∑Â∑•‰ΩúÔºå‰æãÂ¶ÇÈÄèÈÅéÊï∏ÊìöÂàÜÊûêÊ∏õÂ∞ëÁ¢≥ÊéíÊîæ„ÄÅÁõ£Ê∏¨Ê∞£ÂÄôËÆäÂåñÁ≠â„ÄÇ‰Ω†Ë™çÁÇ∫ AI ÈÇÑÂèØ‰ª•Âú®Âì™‰∫õÊñπÈù¢Âπ´Âä©Áí∞Â¢É‰øùË≠∑Ôºü', 'engagement': 255, 'line_count': 3, 'language': 'Mandarin', 'tags': ['Artificial Intelligence', 'Sustainability'], 'tone': 'Neutral'}, {'text': '‡§°‡§ø‡§ú‡§ø‡§ü‡§≤ ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§´‡•â‡§∞‡•ç‡§Æ‡•á‡§∂‡§® ‡§ï‡•á ‡§¶‡•å‡§∞ ‡§Æ‡•á‡§Ç ‡§õ‡•ã‡§ü‡•á ‡§î‡§∞ ‡§Æ‡§ß‡•ç‡§Ø‡§Æ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§¨‡§∏‡•á ‡§ú‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§´‡§æ‡§Ø‡§¶‡§æ ‡§ï‡•à‡§∏‡•á ‡§Æ‡§ø‡§≤ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à? ‡§ï‡•ç‡§Ø‡§æ ‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§î‡§∞ ‡§ü‡•á‡§ï‡•ç‡§®‡•ã‡§≤‡•â‡§ú‡•Ä ‡§è‡§°‡•â‡§™‡•ç‡§∂‡§® ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§ï‡•â‡§∞‡§™‡•ã‡§∞‡•á‡§ü ‡§ï‡§Ç‡§™‡§®‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§Æ‡•Å‡§ï‡§æ‡§¨‡§≤‡•á ‡§ñ‡§°‡§º‡§æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à?', 'engagement': 340, 'line_count': 2, 'language': 'Hindi', 'tags': ['Digital Transformation', 'Small Business'], 'tone': 'Neutral'}, {'text': '¬øC√≥mo la inteligencia artificial est√° impactando la educaci√≥n? Desde herramientas de aprendizaje personalizadas hasta evaluaci√≥n automatizada, la tecnolog√≠a est√° revolucionando el sector educativo. ¬øQu√© opinas sobre el uso de IA en la educaci√≥n?', 'engagement': 412, 'line_count': 3, 'language': 'Spanish', 'tags': ['Learning', 'Artificial Intelligence'], 'tone': 'Neutral'}, {'text': \"L'intelligence artificielle pourrait-elle remplacer les emplois traditionnels? Bien que l'automatisation am√©liore l'efficacit√©, elle soul√®ve des inqui√©tudes concernant l'emploi. Quelles comp√©tences doivent d√©velopper les travailleurs pour rester pertinents dans un monde domin√© par l'IA?\", 'engagement': 287, 'line_count': 3, 'language': 'French', 'tags': ['Automation', 'Artificial Intelligence'], 'tone': 'Neutral'}, {'text': 'ŸÉŸäŸÅ ŸäŸÖŸÉŸÜŸÜÿß ÿ™ÿ≠ŸÇŸäŸÇ ÿ™ÿ≠ŸàŸÑ ÿ±ŸÇŸÖŸä ÿØŸàŸÜ ÿßŸÑÿ™ÿ∂ÿ≠Ÿäÿ© ÿ®ÿßŸÑÿÆÿµŸàÿµŸäÿ©ÿü ŸÅŸä ÿπÿßŸÑŸÖ ŸÖÿ™ÿµŸÑ ÿ®ÿ¥ŸÉŸÑ ŸÖÿ™ÿ≤ÿßŸäÿØÿå ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿ¥ÿÆÿµŸäÿ© ÿ£ÿµÿ®ÿ≠ÿ™ ÿ£ŸÉÿ´ÿ± ÿπÿ±ÿ∂ÿ© ŸÑŸÑÿßÿÆÿ™ÿ±ÿßŸÇ. ŸÖÿß ŸáŸä ÿ£ŸÅÿ∂ŸÑ ÿßŸÑŸÖŸÖÿßÿ±ÿ≥ÿßÿ™ ŸÑÿ≠ŸÖÿßŸäÿ© ÿßŸÑÿÆÿµŸàÿµŸäÿ© ŸÅŸä ÿπÿµÿ± ÿßŸÑÿ™ŸÉŸÜŸàŸÑŸàÿ¨Ÿäÿß ÿßŸÑŸÖÿ™ŸÇÿØŸÖÿ©ÿü', 'engagement': 276, 'line_count': 3, 'language': 'Arabic', 'tags': ['Privacy', 'Digital Transformation'], 'tone': 'Professional'}, {'text': '‡¶ï‡ßã‡¶≠‡¶ø‡¶°-‡¶™‡¶∞‡¶¨‡¶∞‡ßç‡¶§‡ßÄ ‡¶Ø‡ßÅ‡¶ó‡ßá ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø ‡¶∏‡¶ö‡ßá‡¶§‡¶®‡¶§‡¶æ ‡¶ï‡¶§‡¶ü‡¶æ ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶π‡¶Ø‡¶º‡ßá ‡¶â‡¶†‡ßá‡¶õ‡ßá? ‡¶Æ‡¶æ‡¶®‡¶∏‡¶ø‡¶ï ‡¶è‡¶¨‡¶Ç ‡¶∂‡¶æ‡¶∞‡ßÄ‡¶∞‡¶ø‡¶ï ‡¶∏‡ßÅ‡¶∏‡ßç‡¶•‡¶§‡¶æ ‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡¶ø‡¶§ ‡¶ï‡¶∞‡¶§‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶ï‡ßã‡¶® ‡¶®‡¶§‡ßÅ‡¶® ‡¶Ö‡¶≠‡ßç‡¶Ø‡¶æ‡¶∏‡¶ó‡ßÅ‡¶≤‡¶ø ‡¶ó‡ßç‡¶∞‡¶π‡¶£ ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø?', 'engagement': 334, 'line_count': 3, 'language': 'Bengali', 'tags': ['Post Covid Life', 'Health Awareness'], 'tone': 'Neutral'}, {'text': 'A lideran√ßa resiliente √© fundamental para superar desafios econ√¥micos e sociais. Como um bom l√≠der pode manter a moral da equipe alta em tempos de crise?', 'engagement': 415, 'line_count': 2, 'language': 'Portuguese', 'tags': ['Leadership', 'Resilience'], 'tone': 'Professional'}, {'text': '–õ—é–¥–∏ –∏–ª–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: —á—Ç–æ –≤–∞–∂–Ω–µ–µ –¥–ª—è —É—Å–ø–µ—à–Ω–æ–≥–æ –±–∏–∑–Ω–µ—Å–∞? –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Å—á–∏—Ç–∞—é—Ç, —á—Ç–æ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π —Ñ–∞–∫—Ç–æ—Ä –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª—è—é—â–∏–º, –¥—Ä—É–≥–∏–µ –∂–µ —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è ‚Äì —ç—Ç–æ –±—É–¥—É—â–µ–µ. –ê —á—Ç–æ –¥—É–º–∞–µ—Ç–µ –≤—ã?', 'engagement': 390, 'line_count': 3, 'language': 'Russian', 'tags': ['Business', 'Technology'], 'tone': 'Neutral'}, {'text': 'Hinglish: AI ka impact hamari jobs pe kaise padega? Kya aapko lagta hai ki automation naye opportunities create karega ya existing jobs ko replace karega?', 'engagement': 540, 'line_count': 3, 'language': 'Hindi', 'tags': ['Artificial Intelligence', 'Job Search'], 'tone': 'Neutral'}, {'text': 'Work-life balance is essential for mental well-being. With longer working hours and constant digital connectivity, burnout has become a real issue. How do you set boundaries to maintain a healthy balance?', 'engagement': 471, 'line_count': 3, 'language': 'English', 'tags': ['Work-Life Balance', 'Mental Health'], 'tone': 'Professional'}, {'text': 'Êï∏Â≠óÂâµÊñ∞Â¶Ç‰ΩïÂπ´Âä©ÂâµÊ•≠ÂÖ¨Âè∏Âø´ÈÄüÁôºÂ±ïÔºüÂæûÈõ≤Ë®àÁÆóÂà∞ÂçÄÂ°äÈèàÔºåÊäÄË°ìÁÇ∫ÂàùÂâµ‰ºÅÊ•≠Êèê‰æõ‰∫ÜÂâçÊâÄÊú™ÊúâÁöÑÊ©üÊúÉ„ÄÇ‰Ω†Ë™çÁÇ∫Âì™Á®ÆÊäÄË°ìÂ∞çÂâµÊ•≠ÊúÄÊúâÂπ´Âä©Ôºü', 'engagement': 238, 'line_count': 3, 'language': 'Mandarin', 'tags': ['Entrepreneurship'], 'tone': 'Professional'}, {'text': '‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡§π‡§ø‡§≤‡§æ‡§è‡§Å ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§∏‡•ç‡§•‡§≤ ‡§™‡§∞ ‡§∏‡§Æ‡§æ‡§® ‡§Ö‡§µ‡§∏‡§∞ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•à‡§Ç? ‡§≠‡§≤‡•á ‡§π‡•Ä ‡§≤‡•à‡§Ç‡§ó‡§ø‡§ï ‡§∏‡§Æ‡§æ‡§®‡§§‡§æ ‡§ï‡•Ä ‡§¶‡§ø‡§∂‡§æ ‡§Æ‡•á‡§Ç ‡§ï‡§æ‡§´‡•Ä ‡§™‡•ç‡§∞‡§ó‡§§‡§ø ‡§π‡•Å‡§à ‡§π‡•à, ‡§´‡§ø‡§∞ ‡§≠‡•Ä ‡§ï‡§à ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§Ö‡§≠‡•Ä ‡§≠‡•Ä ‡§Ö‡§∏‡§Æ‡§æ‡§®‡§§‡§æ ‡§¨‡§®‡•Ä ‡§π‡•Å‡§à ‡§π‡•à‡•§ ‡§Ü‡§™‡§ï‡•Ä ‡§∞‡§æ‡§Ø ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è?', 'engagement': 315, 'line_count': 5, 'language': 'Hindi', 'tags': ['Diversity', 'Workplace'], 'tone': 'Inspirational'}, {'text': '¬øEs posible lograr un mundo sin contaminaci√≥n? Desde el reciclaje hasta la energ√≠a renovable, hay muchas soluciones. Pero, ¬øestamos realmente haciendo lo suficiente para abordar el problema ambiental?', 'engagement': 502, 'line_count': 3, 'language': 'Spanish', 'tags': ['Environmental Impact', 'Sustainability'], 'tone': 'Inspirational'}, {'text': \"Les √©nergies renouvelables sont-elles la solution au changement climatique? Le solaire, l'√©olien et l'hydro√©lectrique gagnent en popularit√©, mais leur adoption reste limit√©e. Que faudrait-il faire pour acc√©l√©rer leur utilisation?\", 'engagement': 428, 'line_count': 4, 'language': 'French', 'tags': ['Climate Change', 'Sustainability'], 'tone': 'Neutral'}, {'text': 'ŸÉŸäŸÅ ŸäŸÖŸÉŸÜ ŸÑŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ÿ™ÿπÿ≤Ÿäÿ≤ ÿßŸÑÿßŸÇÿ™ÿµÿßÿØ ÿßŸÑÿπÿßŸÑŸÖŸäÿü ŸÖŸÜ ÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑŸÉŸÅÿßÿ°ÿ© ÿ•ŸÑŸâ ÿÆŸÑŸÇ Ÿàÿ∏ÿßÿ¶ŸÅ ÿ¨ÿØŸäÿØÿ©ÿå ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸÑÿØŸäŸá ÿßŸÑŸÇÿØÿ±ÿ© ÿπŸÑŸâ ÿ™ÿ∫ŸäŸäÿ± ÿßŸÑŸÖÿ¥ŸáÿØ ÿßŸÑÿßŸÇÿ™ÿµÿßÿØŸä ÿ®ÿßŸÑŸÉÿßŸÖŸÑ. ŸÉŸäŸÅ ÿ™ÿ±Ÿâ ŸÖÿ≥ÿ™ŸÇÿ®ŸÑ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸÅŸä ÿßŸÑÿßŸÇÿ™ÿµÿßÿØÿü', 'engagement': 359, 'line_count': 3, 'language': 'Arabic', 'tags': ['Economy', 'Artificial Intelligence'], 'tone': 'Inspirational'}, {'text': 'A automa√ß√£o pode criar mais empregos do que destruir? Embora muitas tarefas manuais estejam sendo substitu√≠das, novas oportunidades surgem. Como podemos garantir que ningu√©m fique para tr√°s?', 'engagement': 375, 'line_count': 3, 'language': 'Portuguese', 'tags': ['Automation', 'Job Creation'], 'tone': 'Neutral'}, {'text': \"After numerous rejections, I discovered that every 'no' brings me closer to the right 'yes.' Embrace setbacks as lessons for future success. Let your failures guide you toward greater achievements.\", 'engagement': 320, 'line_count': 3, 'language': 'English', 'tags': ['Motivation', 'Success'], 'tone': 'Inspirational'}, {'text': 'Âú®Êï∞Â≠óÊó∂‰ª£ÔºåÊåÅÁª≠Â≠¶‰π†ÂèòÂæóÊØî‰ª•ÂæÄ‰ªª‰ΩïÊó∂ÂÄôÈÉΩÈáçË¶Å„ÄÇÈù¢ÂØπ‰∏çÊñ≠ÂèòÂåñÁöÑÂ∏ÇÂú∫ÂíåÊäÄÊúØÔºå‰øùÊåÅÁ´û‰∫âÂäõÈúÄË¶Å‰∏çÊñ≠ËøõÊ≠•„ÄÇ‰Ω†Â¶Ç‰ΩïÂú®ËÅå‰∏öÁîüÊ∂Ø‰∏≠‰øùÊåÅÂ≠¶‰π†ÁöÑÁÉ≠ÊÉÖÔºü', 'engagement': 280, 'line_count': 3, 'language': 'Mandarin', 'tags': ['Learning', 'Career Development'], 'tone': 'Inspirational'}, {'text': 'Remote work has redefined traditional office culture. It challenges us to find innovative ways to connect, collaborate, and stay inspired despite physical distance. What strategies have you found effective?', 'engagement': 410, 'line_count': 3, 'language': 'English', 'tags': ['Office Culture', 'Remote Work'], 'tone': 'Professional'}, {'text': '‡§µ‡§ø‡§µ‡§ø‡§ß‡§§‡§æ ‡§î‡§∞ ‡§∏‡§Æ‡§æ‡§µ‡•á‡§∂‡§ø‡§§‡§æ ‡§∏‡•á ‡§≠‡§∞‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§∏‡•ç‡§•‡§≤ ‡§® ‡§ï‡•á‡§µ‡§≤ ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§ï‡§§‡§æ ‡§¨‡§¢‡§º‡§æ‡§§‡•Ä ‡§π‡•à, ‡§¨‡§≤‡•ç‡§ï‡§ø ‡§®‡§à ‡§∏‡•ã‡§ö ‡§î‡§∞ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§≠‡•Ä ‡§™‡•à‡§¶‡§æ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§Ö‡§™‡§®‡•á ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§∏‡•ç‡§•‡§≤ ‡§Æ‡•á‡§Ç ‡§á‡§∏ ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§ï‡•ã ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç?', 'engagement': 370, 'line_count': 3, 'language': 'Hindi', 'tags': ['Diversity'], 'tone': 'Inspirational'}, {'text': 'La transformaci√≥n digital es un viaje continuo, lleno de aprendizajes y desaf√≠os. Cada paso hacia la innovaci√≥n abre nuevas oportunidades y plantea preguntas. ¬øCu√°l ha sido tu mayor aprendizaje en este camino?', 'engagement': 335, 'line_count': 3, 'language': 'Spanish', 'tags': ['Learning', 'Innovation'], 'tone': 'Inspirational'}, {'text': \"L'importance de l'innovation dans le secteur de la sant√© ne peut √™tre sous-estim√©e. Les technologies √©mergentes offrent des solutions r√©volutionnaires, mais posent √©galement des d√©fis √©thiques. Quelle est votre perspective?\", 'engagement': 395, 'line_count': 3, 'language': 'French', 'tags': ['Health Awareness', 'Innovation'], 'tone': 'Neutral'}, {'text': 'ÿßŸÑÿ™ÿ≠ÿØŸäÿßÿ™ ŸÅŸä ÿπÿßŸÑŸÖ ÿßŸÑÿπŸÖŸÑ ÿßŸÑÿ≠ÿØŸäÿ´ ÿ™ÿ™ÿ∑ŸÑÿ® ŸÖÿ±ŸàŸÜÿ© Ÿàÿ™ŸÅŸÉŸäÿ± ŸÖÿ®ÿ™ŸÉÿ±. ŸÉŸÑ ŸäŸàŸÖ Ÿäÿ≠ŸÖŸÑ ŸÖÿπŸá ŸÅÿ±ÿµÿ© ŸÑÿ™ÿπŸÑŸÖ ÿ¥Ÿäÿ° ÿ¨ÿØŸäÿØ Ÿàÿ™ÿ≠ÿØŸä ÿßŸÑŸÇŸäŸàÿØ ÿßŸÑÿ™ŸÇŸÑŸäÿØŸäÿ©. ŸÉŸäŸÅ ÿ™Ÿàÿßÿ¨Ÿá ÿ™ÿ≠ÿØŸäÿßÿ™ ÿßŸÑÿπŸÖŸÑ ÿßŸÑŸäŸàŸÖŸäÿ© ŸÅŸä ÿ®Ÿäÿ¶ÿ© ŸÖÿ™ÿ∫Ÿäÿ±ÿ©ÿü', 'engagement': 360, 'line_count': 4, 'language': 'Arabic', 'tags': ['Career Development', 'Innovation'], 'tone': 'Inspirational'}, {'text': '‡¶™‡ßç‡¶∞‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø‡¶∞ ‡¶Ö‡¶ó‡ßç‡¶∞‡¶ó‡¶§‡¶ø ‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ ‡¶ú‡ßÄ‡¶¨‡¶®‡ßá ‡¶¨‡¶ø‡¶™‡ßç‡¶≤‡¶¨ ‡¶ò‡¶ü‡¶ø‡ßü‡ßá‡¶õ‡ßá‡•§ ‡¶ï‡¶∞‡ßç‡¶Æ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡¶∞‡ßá ‡¶®‡¶§‡ßÅ‡¶® ‡¶™‡ßç‡¶∞‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø‡¶∞ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶∏‡ßÉ‡¶ú‡¶®‡¶∂‡ßÄ‡¶≤‡¶§‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶¶‡¶ï‡ßç‡¶∑‡¶§‡¶æ ‡¶¨‡ßÉ‡¶¶‡ßç‡¶ß‡¶ø‡¶§‡ßá ‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶ï‡•§ ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶ú‡ßá‡¶∞ ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡¶∞‡ßá ‡¶™‡ßç‡¶∞‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø‡¶∞ ‡¶™‡ßç‡¶∞‡¶≠‡¶æ‡¶¨ ‡¶ï‡ßá‡¶Æ‡¶®?', 'engagement': 310, 'line_count': 3, 'language': 'Bengali', 'tags': ['Workplace', 'Technology'], 'tone': 'Neutral'}, {'text': 'A sustentabilidade n√£o √© apenas uma meta ambiental, mas uma responsabilidade que devemos assumir coletivamente. Empresas e indiv√≠duos podem fazer a diferen√ßa adotando pr√°ticas sustent√°veis. Qual √© a sua contribui√ß√£o?', 'engagement': 420, 'line_count': 5, 'language': 'Portuguese', 'tags': ['Responsibility', 'Sustainability'], 'tone': 'Professional'}, {'text': '–£—Å–ø–µ—Ö –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º –±–∏–∑–Ω–µ—Å–µ —Ç—Ä–µ–±—É–µ—Ç –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫ –Ω–æ–≤—ã–º —É—Å–ª–æ–≤–∏—è–º. –ö–∞–∫–∏–µ –Ω–∞–≤—ã–∫–∏ –≤—ã —Ä–∞–∑–≤–∏–≤–∞–µ—Ç–µ, —á—Ç–æ–±—ã –æ—Å—Ç–∞–≤–∞—Ç—å—Å—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ—Å–ø–æ—Å–æ–±–Ω—ã–º –≤ —ç—Ç–æ–º —Å—Ç—Ä–µ–º–∏—Ç–µ–ª—å–Ω–æ –º–µ–Ω—è—é—â–µ–º—Å—è –º–∏—Ä–µ?', 'engagement': 380, 'line_count': 3, 'language': 'Russian', 'tags': ['Business', 'Success'], 'tone': 'Professional'}, {'text': 'Hinglish: Networking ka matlab sirf contacts banana nahi, balki ek dusre ke growth me contribute karna bhi hai. Aap apne network se kya naya seekh rahe hain, aur kaise apni journey ko enrich kar rahe hain?', 'engagement': 440, 'line_count': 3, 'language': 'Hindi', 'tags': ['Networking', 'Personal Growth'], 'tone': 'Inspirational'}, {'text': 'Digital transformation is reshaping industries globally, creating new paradigms in business strategy and operations. How are you leveraging emerging technologies to drive innovation and growth in your organization?', 'engagement': 405, 'line_count': 2, 'language': 'English', 'tags': ['Digital Transformation', 'Emerging Technologies'], 'tone': 'Professional'}, {'text': '‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÁöÑËøÖÈÄüÂèëÂ±ï‰∏∫ÂêÑË°åÂêÑ‰∏öÂ∏¶Êù•‰∫ÜÊú∫ÈÅá‰∏éÊåëÊàò„ÄÇÈô§‰∫ÜÊèêÂçáÊïàÁéáÔºåÂ¶Ç‰ΩïÁ°Æ‰øùÊï∞ÊçÆÂÆâÂÖ®ÂíåÈöêÁßÅ‰øùÊä§Êàê‰∏∫‰∫ÜÊñ∞ÁöÑËØæÈ¢ò„ÄÇ‰Ω†ÂØπÊú™Êù•ÁöÑAIÂ∫îÁî®Êúâ‰ΩïÊúüÂæÖÔºü', 'engagement': 350, 'line_count': 5, 'language': 'Mandarin', 'tags': ['Data Security', 'Artificial Intelligence'], 'tone': 'Neutral'}, {'text': '‡§°‡§ø‡§ú‡§ø‡§ü‡§≤ ‡§Ø‡•Å‡§ó ‡§Æ‡•á‡§Ç ‡§∏‡§´‡§≤‡§§‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§ø‡§∞‡§Ç‡§§‡§∞ ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§î‡§∞ ‡§∏‡•ç‡§µ‡§Ø‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§°‡•á‡§ü ‡§∞‡§ñ‡§®‡§æ ‡§Ö‡§®‡§ø‡§µ‡§æ‡§∞‡•ç‡§Ø ‡§π‡•à‡•§ ‡§¨‡§¶‡§≤‡§§‡•á ‡§∏‡§Æ‡§Ø ‡§ï‡•á ‡§∏‡§æ‡§• ‡§§‡§æ‡§≤‡§Æ‡•á‡§≤ ‡§¨‡§ø‡§†‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•ç‡§Ø‡§æ ‡§∞‡§£‡§®‡•Ä‡§§‡§ø ‡§π‡•à?', 'engagement': 395, 'line_count': 3, 'language': 'Hindi', 'tags': ['Digital Age', 'Sustainability'], 'tone': 'Neutral'}, {'text': 'La importancia de la resiliencia en tiempos de incertidumbre es m√°s evidente que nunca. Cada desaf√≠o es una oportunidad para crecer y aprender. ¬øC√≥mo te fortaleces ante las adversidades?', 'engagement': 430, 'line_count': 3, 'language': 'Spanish', 'tags': ['Growth', 'Resilience'], 'tone': 'Inspirational'}, {'text': \"L'innovation et l'adaptation sont essentielles pour naviguer dans le paysage professionnel moderne. Adoptez le changement comme une opportunit√© pour progresser et enrichir vos comp√©tences.\", 'engagement': 390, 'line_count': 3, 'language': 'French', 'tags': ['Adaptation', 'Innovation'], 'tone': 'Inspirational'}, {'text': 'ÿßŸÑÿπÿßŸÑŸÖ ÿßŸÑÿ±ŸÇŸÖŸä Ÿäÿ™ÿ∫Ÿäÿ± ÿ®ÿ≥ÿ±ÿπÿ©ÿå ŸàŸÖÿπ ŸÉŸÑ ÿ™ÿ∫ŸäŸäÿ± ÿ™ÿ£ÿ™Ÿä ŸÅÿ±ÿµ ÿ¨ÿØŸäÿØÿ© Ÿàÿ™ÿ≠ÿØŸäÿßÿ™ ŸÖÿ™ÿ¨ÿØÿØÿ©. ŸÉŸäŸÅ ÿ™ÿ≥ÿ™ÿπÿØ ŸÑŸÖŸàÿßÿ¨Ÿáÿ© ÿ™ÿ≠ÿØŸäÿßÿ™ ÿßŸÑŸÖÿ≥ÿ™ŸÇÿ®ŸÑ ŸÅŸä ÿπÿµÿ± ÿßŸÑÿ™ŸÇŸÜŸäÿ© ÿßŸÑŸÖÿ™ÿ∑Ÿàÿ±ÿ©ÿü', 'engagement': 415, 'line_count': 2, 'language': 'Arabic', 'tags': ['Future', 'Technology'], 'tone': 'Inspirational'}]\n"
     ]
    }
   ],
   "source": [
    "# json loader \n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "file_path='./data/sample.json'\n",
    "data = json.loads(Path(file_path).read_text())\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-unstructured in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.6)\n",
      "Collecting unstructured\n",
      "  Obtaining dependency information for unstructured from https://files.pythonhosted.org/packages/4d/54/f9a44bb1ea187e20566a72e8ebecd16b5b9d72c60536f33083e9954cd069/unstructured-0.17.0-py3-none-any.whl.metadata\n",
      "  Downloading unstructured-0.17.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-unstructured) (0.3.45)\n",
      "Requirement already satisfied: onnxruntime<=1.19.2,>=1.17.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-unstructured) (1.19.2)\n",
      "Requirement already satisfied: unstructured-client<1,>=0.27.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-unstructured) (0.31.1)\n",
      "Collecting chardet (from unstructured)\n",
      "  Obtaining dependency information for chardet from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured)\n",
      "  Obtaining dependency information for filetype from https://files.pythonhosted.org/packages/18/79/1b8fa1bb3568781e84c9200f951c735f3f157429f44be0495da55894d620/filetype-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Obtaining dependency information for python-magic from https://files.pythonhosted.org/packages/6c/73/9f872cb81fc5c3bb48f7227872c28975f998f3e7c2b1c16e95e6432bbb90/python_magic-0.4.27-py2.py3-none-any.whl.metadata\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Obtaining dependency information for lxml from https://files.pythonhosted.org/packages/12/8c/7d47cfc0d04fd4e3639ec7e1c96c2561d5e890eb900de8f76eea75e0964a/lxml-5.3.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading lxml-5.3.1-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting nltk (from unstructured)\n",
      "  Obtaining dependency information for nltk from https://files.pythonhosted.org/packages/4d/66/7d9e26593edda06e8cb531874633f7c2372279c3b0f46235539fe546df8b/nltk-3.9.1-py3-none-any.whl.metadata\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (4.12.2)\n",
      "Collecting emoji (from unstructured)\n",
      "  Obtaining dependency information for emoji from https://files.pythonhosted.org/packages/91/db/a0335710caaa6d0aebdaa65ad4df789c15d89b7babd9a30277838a7d9aac/emoji-2.14.1-py3-none-any.whl.metadata\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (0.6.7)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Obtaining dependency information for python-iso639 from https://files.pythonhosted.org/packages/54/a3/3ceaf89a17a1e1d5e7bbdfe5514aa3055d91285b37a5c8fed662969e3d56/python_iso639-2025.2.18-py3-none-any.whl.metadata\n",
      "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     --------- ---------------------------- 235.5/981.5 kB 7.3 MB/s eta 0:00:01\n",
      "     ------------------------- ------------ 665.6/981.5 kB 8.4 MB/s eta 0:00:01\n",
      "     -------------------------------------  972.8/981.5 kB 8.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- 981.5/981.5 kB 7.8 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting numpy<2 (from unstructured)\n",
      "  Obtaining dependency information for numpy<2 from https://files.pythonhosted.org/packages/3f/6b/5610004206cf7f8e7ad91c5a85a8c71b2f2f8051a0c0c4d5916b76d6cbb2/numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.0/61.0 kB ? eta 0:00:00\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Obtaining dependency information for rapidfuzz from https://files.pythonhosted.org/packages/38/4c/faacecf70a4e202a02f029ec6f6e04e910d95c4ef36d7d63b83b160f7f3e/rapidfuzz-3.12.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading rapidfuzz-3.12.2-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Obtaining dependency information for backoff from https://files.pythonhosted.org/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl.metadata\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (4.12.2)\n",
      "Collecting wrapt (from unstructured)\n",
      "  Obtaining dependency information for wrapt from https://files.pythonhosted.org/packages/47/f8/fb1773491a253cbc123c5d5dc15c86041f746ed30416535f2a8df1f4a392/wrapt-1.17.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured) (7.0.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Obtaining dependency information for python-oxmsg from https://files.pythonhosted.org/packages/53/67/f56c69a98c7eb244025845506387d0f961681657c9fcd8b2d2edd148f9d2/python_oxmsg-0.0.2-py3-none-any.whl.metadata\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Obtaining dependency information for html5lib from https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl.metadata\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.3.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.10.6)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (6.30.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (1.13.3)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (44.0.2)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (0.2.2)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\users\\choud\\appdata\\roaming\\python\\python311\\site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (1.6.0)\n",
      "Requirement already satisfied: pypdf>=4.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (5.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\choud\\appdata\\roaming\\python\\python311\\site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (2.9.0.post0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (1.0.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (0.4.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->unstructured) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from html5lib->unstructured) (1.17.0)\n",
      "Collecting webencodings (from html5lib->unstructured)\n",
      "  Obtaining dependency information for webencodings from https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl.metadata\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: click in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->unstructured) (8.1.7)\n",
      "Collecting joblib (from nltk->unstructured)\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->unstructured) (2024.11.6)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Obtaining dependency information for olefile from https://files.pythonhosted.org/packages/17/d3/b64c356a907242d719fc668b71befd73324e47ab46c8ebbbede252c154b2/olefile-0.47-py2.py3-none-any.whl.metadata\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->unstructured) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->unstructured) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->unstructured) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->unstructured) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->unstructured) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=3.1->unstructured-client<1,>=0.27.0->langchain-unstructured) (1.16.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain-unstructured) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain-unstructured) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain-unstructured) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.10.15)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from coloredlogs->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (1.3.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client<1,>=0.27.0->langchain-unstructured) (2.21)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (3.5.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain-unstructured) (1.3.0)\n",
      "Downloading unstructured-0.17.0-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.6/1.8 MB 19.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 14.1 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/15.8 MB 21.1 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 2.0/15.8 MB 20.8 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 2.6/15.8 MB 18.2 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.8/15.8 MB 16.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 3.1/15.8 MB 13.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 3.3/15.8 MB 12.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.5/15.8 MB 10.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.6/15.8 MB 10.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.7/15.8 MB 9.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.8/15.8 MB 8.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.9/15.8 MB 7.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.9/15.8 MB 7.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.0/15.8 MB 6.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.1/15.8 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.1/15.8 MB 6.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.2/15.8 MB 6.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.3/15.8 MB 5.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.5/15.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.6/15.8 MB 5.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.7/15.8 MB 5.3 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.9/15.8 MB 5.2 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 5.1/15.8 MB 5.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 5.3/15.8 MB 5.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 5.4/15.8 MB 5.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.6/15.8 MB 5.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.9/15.8 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.1/15.8 MB 5.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.4/15.8 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.6/15.8 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 7.0/15.8 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.3/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.6/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.9/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 8.1/15.8 MB 5.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.4/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.6/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.8/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 9.0/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.2/15.8 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.4/15.8 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.6/15.8 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.7/15.8 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 10.0/15.8 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 10.2/15.8 MB 5.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 10.5/15.8 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 10.7/15.8 MB 4.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 11.0/15.8 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.3/15.8 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.6/15.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.9/15.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.2/15.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.4/15.8 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.6/15.8 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.9/15.8 MB 4.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.1/15.8 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.4/15.8 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.7/15.8 MB 4.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.0/15.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.2/15.8 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.4/15.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.8 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.8/15.8 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.9/15.8 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.1/15.8 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.3/15.8 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.4/15.8 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.6/15.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "   ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 143.4/199.4 kB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 199.4/199.4 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 194.6/590.6 kB 5.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 409.6/590.6 kB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 590.6/590.6 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "   ---------------------------------------- 0.0/112.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 112.2/112.2 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading lxml-5.3.1-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.2/3.8 MB 5.9 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.4/3.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.7/3.8 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.2/3.8 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.6/3.8 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.9/3.8 MB 5.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.2/3.8 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.6/3.8 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.9/3.8 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.3/3.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.7/3.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 6.6 MB/s eta 0:00:00\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.4/1.5 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.9/1.5 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 6.9 MB/s eta 0:00:00\n",
      "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "   ---------------------------------------- 0.0/167.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 167.6/167.6 kB 10.5 MB/s eta 0:00:00\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading rapidfuzz-3.12.2-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.2/1.6 MB 6.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.6 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.7/1.6 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.9/1.6 MB 5.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.1/1.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.3/1.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.4/1.6 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.5/1.6 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.6/1.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading wrapt-1.17.2-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 112.6/301.8 kB 3.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 256.0/301.8 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 301.8/301.8 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "   ---------------------------------------- 0.0/114.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 114.6/114.6 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (pyproject.toml): started\n",
      "  Building wheel for langdetect (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993313 sha256=e56e51ff28d659886b73996a4eb412ef2351fca34416d22d08beeecd7319d388\n",
      "  Stored in directory: c:\\users\\choud\\appdata\\local\\pip\\cache\\wheels\\0a\\f2\\b2\\e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "Successfully built langdetect\n",
      "Installing collected packages: webencodings, filetype, wrapt, rapidfuzz, python-magic, python-iso639, olefile, numpy, lxml, langdetect, joblib, html5lib, emoji, chardet, backoff, python-oxmsg, nltk, unstructured\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.4\n",
      "    Uninstalling numpy-2.2.4:\n",
      "      Successfully uninstalled numpy-2.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\choud\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\~umpy.libs\\\\libscipy_openblas64_-43e11ff0749b8cbe0a615c9cf6737e0e.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain-unstructured unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "unstructured package not found, please install it with `pip install unstructured`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\choud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_unstructured\\document_loaders.py:236\u001b[39m, in \u001b[36m_SingleDocumentLoader._elements_via_local\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m partition  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'unstructured'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m loader = UnstructuredLoader(web_url=page_url)\n\u001b[32m      7\u001b[39m docs = []\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m loader.alazy_load():\n\u001b[32m      9\u001b[39m     docs.append(doc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\choud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:83\u001b[39m, in \u001b[36mBaseLoader.alazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     81\u001b[39m done = \u001b[38;5;28mobject\u001b[39m()\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     doc = \u001b[38;5;28;01mawait\u001b[39;00m run_in_executor(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mnext\u001b[39m, iterator, done)  \u001b[38;5;66;03m# type: ignore[call-arg, arg-type]\u001b[39;00m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m done:\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\choud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\config.py:588\u001b[39m, in \u001b[36mrun_in_executor\u001b[39m\u001b[34m(executor_or_config, func, *args, **kwargs)\u001b[39m\n\u001b[32m    584\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m executor_or_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(executor_or_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    587\u001b[39m     \u001b[38;5;66;03m# Use default executor with context copied from current context\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.get_running_loop().run_in_executor(\n\u001b[32m    589\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    590\u001b[39m         cast(Callable[..., T], partial(copy_context().run, wrapper)),\n\u001b[32m    591\u001b[39m     )\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.get_running_loop().run_in_executor(executor_or_config, wrapper)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\choud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\choud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\config.py:579\u001b[39m, in \u001b[36mrun_in_executor.<locals>.wrapper\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m() -> T:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    581\u001b[39m         \u001b[38;5;66;03m# StopIteration can't be set on an asyncio.Future\u001b[39;00m\n\u001b[32m    582\u001b[39m         \u001b[38;5;66;03m# it raises a TypeError and leaves the Future pending forever\u001b[39;00m\n\u001b[32m    583\u001b[39m         \u001b[38;5;66;03m# so we need to convert it to a RuntimeError\u001b[39;00m\n\u001b[32m    584\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\choud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_unstructured\\document_loaders.py:178\u001b[39m, in \u001b[36mUnstructuredLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# Call _UnstructuredBaseLoader normally since file and file_path are not lists\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m load_file(f=\u001b[38;5;28mself\u001b[39m.file, f_path=\u001b[38;5;28mself\u001b[39m.file_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\choud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_unstructured\\document_loaders.py:212\u001b[39m, in \u001b[36m_SingleDocumentLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[Document]:\n\u001b[32m    208\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[32m    209\u001b[39m     elements_json = (\n\u001b[32m    210\u001b[39m         \u001b[38;5;28mself\u001b[39m._post_process_elements_json(\u001b[38;5;28mself\u001b[39m._elements_json)\n\u001b[32m    211\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.post_processors\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_elements_json\u001b[49m\n\u001b[32m    213\u001b[39m     )\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m elements_json:\n\u001b[32m    215\u001b[39m         metadata = \u001b[38;5;28mself\u001b[39m._get_metadata()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\choud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_unstructured\\document_loaders.py:231\u001b[39m, in \u001b[36m_SingleDocumentLoader._elements_json\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partition_via_api:\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._elements_via_api\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._convert_elements_to_dicts(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_elements_via_local\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\choud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_unstructured\\document_loaders.py:238\u001b[39m, in \u001b[36m_SingleDocumentLoader._elements_via_local\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m partition  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    239\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33munstructured package not found, please install it with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    240\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`pip install unstructured`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    241\u001b[39m     )\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.file \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unstructured_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata_filename\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    245\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf partitioning a fileIO object, metadata_filename must be specified\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m as well.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    247\u001b[39m     )\n",
      "\u001b[31mImportError\u001b[39m: unstructured package not found, please install it with `pip install unstructured`"
     ]
    }
   ],
   "source": [
    "# webpage\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "page_url = \"https://python.langchain.com/docs/how_to/chatbots_memory/\"\n",
    "loader = UnstructuredLoader(web_url=page_url)\n",
    "\n",
    "docs = []\n",
    "async for doc in loader.alazy_load():\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "# semantic search engine -> closest related documents \n",
    "# other variation of this is keyword search -> this is exact matching documents\n",
    "# flow -> takes data from source -> chunks -> embeds -> indexes -> searches\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"./data/sample.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunk overlap help us not loose context <- very important\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\",api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-anthropic\n",
      "  Obtaining dependency information for langchain-anthropic from https://files.pythonhosted.org/packages/f4/aa/ca26a13aff12228cb3123cdaf23ee19ffa759102146fb81e3c3bccc599ef/langchain_anthropic-0.3.10-py3-none-any.whl.metadata\n",
      "  Downloading langchain_anthropic-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting anthropic<1,>=0.49.0 (from langchain-anthropic)\n",
      "  Obtaining dependency information for anthropic<1,>=0.49.0 from https://files.pythonhosted.org/packages/76/74/5d90ad14d55fbe3f9c474fdcb6e34b4bed99e3be8efac98734a5ddce88c1/anthropic-0.49.0-py3-none-any.whl.metadata\n",
      "  Downloading anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-anthropic) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-anthropic) (2.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-anthropic) (0.3.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-anthropic) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-anthropic) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-anthropic) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-anthropic) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (2.27.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.49.0->langchain-anthropic) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.49.0->langchain-anthropic) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.49.0->langchain-anthropic) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<1,>=0.49.0->langchain-anthropic) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-anthropic) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-anthropic) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-anthropic) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-anthropic) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-anthropic) (0.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-anthropic) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\choud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-anthropic) (2.1.0)\n",
      "Downloading langchain_anthropic-0.3.10-py3-none-any.whl (25 kB)\n",
      "Downloading anthropic-0.49.0-py3-none-any.whl (243 kB)\n",
      "   ---------------------------------------- 0.0/243.4 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 215.0/243.4 kB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 243.4/243.4 kB 5.0 MB/s eta 0:00:00\n",
      "Installing collected packages: anthropic, langchain-anthropic\n",
      "Successfully installed anthropic-0.49.0 langchain-anthropic-0.3.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain-anthropic\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "ChatAnthropic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f23d924e-4222-4a8e-8f8a-5007434f7eaa', '6f82f698-8e40-4092-bb25-847c767a4fbb', '656efb13-464a-40c7-aac1-6db45da1fa2c', 'd5b80368-e1c0-4d44-bf7c-46a1454c6af0', 'e9c14400-ae2c-4cc3-a65d-96f12fc2fd5f', '2546ba98-d1a0-4d5e-8b1e-9432006eddb4', '6ea55537-26bb-43ea-a793-acc885cce45b', 'f3473c09-afef-46ac-ad21-2b47c7a62f02', '73320d85-ee8f-4b86-8340-b8ef1b8a9cbf', 'ed0698ed-93e3-40a8-96ba-c93d2bef7002', '4a3d669b-a5af-46d5-b5c1-e554f642d976', '84b3bf17-85c3-42b8-9f8a-e87938409e5e', '29556e36-5675-47e6-aefd-b50a7b0106dc', '783fdc9c-2bdf-4fa1-b93c-a41ee7f332b5', '4e331452-e14c-499b-9da0-7c50c1ba3ac0', '8f8347c3-0c50-4ec6-9060-d2d2a195fe63', '3b3f94d5-c4bb-41d8-ab52-773ab3c2e6b6', '05941918-3c29-4d47-8d1c-f58f2b8a8a30', '1cc30ce1-fd7e-43e7-b977-6ed5afe79047', '270eafae-3ed0-4fa6-b7cf-16eaa3323d79', '53301d83-89b7-4c0a-9dc6-5e09cb113be3', 'f95b1ab6-8c9c-4442-bb3c-b60c21192607', '31080951-314b-4c93-bc3d-aa5e75ebbe9e', 'a1f06b7b-c8dc-4e69-89ed-c18db2452dfb', '716a23ff-841a-4fdc-96aa-d7c11aa04ea9', 'b0114376-f165-46ae-8490-7d7d0e7d9fba', '11ba5f6a-6c2b-482c-82c4-b1f48533611a', 'd13606fb-cea0-46ae-8758-d1ebaf0af5de', '7b9a2cf7-df3f-4964-90ec-e9edf223a3bd', '964a02c3-78de-478e-8b52-d0fcd46fc9b4', '0458ef7a-de20-4a9c-a167-963727cf560a', '8e357121-8c84-45d8-b746-5c7bdd7c2714', '846aa2af-0507-4ba3-aec7-a16389b8fff5', 'fef8ce7e-330b-406f-9c08-82fd3dd8c808', '219c7c25-2c07-41cd-93c2-2afae69af788']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "ids = vector_store.add_documents(documents=all_splits)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='ed0698ed-93e3-40a8-96ba-c93d2bef7002', metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3', 'start_index': 0}, page_content=\"BUDGET PROCESS\\nINTERIM BUDGET 2024-25\\nGeneral Discussuion \\non Budget in both the \\nHouses\\nDetalied discussion and \\nvoting on Demand for \\nGrants in Lok sabha \\nBudget is\\npresented\\nStanding Committees \\nscrutinise individual ministers' \\nDemand for  Grants\\nAppropriation and \\nFinance Bill passed\\nSince 2024 is an election year, instead of a normal budget, an interim budget will be presented \\nthis year.\\nInterim budget: It is a short-term financial plan that covers government expenses until the \\nelections.\\nUnlike a normal budget, which covers every aspect of government finances, including revenues, \\nexpenditures, allocations, and policy statements, interim budget only outlines the government‚Äôs \\nanticipated revenues and expenses until the new government is formed.\\nAs part of Interim budget, the Parliament passes a vote-on-account.\\nVote-on-account : According to Article 116 of the Constitution, a vote-on-account represents an\"), Document(id='d5b80368-e1c0-4d44-bf7c-46a1454c6af0', metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1', 'start_index': 2310}, page_content='Expenditure Budget\\nReceipt Budget\\nExpenditure Profile\\nBudget at a Glance\\nKey Features of Budget 2024-25\\nImplementation of Budget Announcements, 2023-24\\nONLINE  |  DELHI  |  AHMEDABAD  |  BHOPAL  |  CHANDIGARH  |  GUWAHATI  |  HYDERABAD  |  JAIPUR  |  JODHPUR  |  LUCKNOW  |  PRAYAGRAJ  |  PUNE  |  RANCHI  |  SIKAR 1\\n2024-25\\nUNION  INTERIM\\nSUMMARY OF'), Document(id='f3473c09-afef-46ac-ad21-2b47c7a62f02', metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2', 'start_index': 2292}, page_content='Expenditure Budget\\nReceipt Budget\\nExpenditure Profile\\nBudget at a Glance\\nKey Features of Budget 2024-25\\nImplementation of Budget Announcements, 2023-24\\nUnion Interim Budget 2024-25\\nONLINE  |  DELHI  |  AHMEDABAD  |  BHOPAL  |  CHANDIGARH  |  GUWAHATI  |  HYDERABAD  |  JAIPUR  |  JODHPUR  |  LUCKNOW  |  PRAYAGRAJ  |  PUNE  |  RANCHI  |  SIKAR 2\\nHISTORY OF BUDGET\\nPre Independence:\\nBudget was first introduced on 7th \\nApril, 1860, two years after the \\ntransfer of Indian administration from  \\nEast-India Company to British Crown.\\nThe first Finance Member, who \\npresented the Budget, was James \\nWilson.\\nMr Liaquat Ali Khan, member of the \\ninterim Government presented the \\nbudget of 1947-48.\\nPost-Independence:\\nIndia‚Äôs first Finance Minister Shri R.K. \\nShanmukham Chetty, presented the \\nfirst Budget on 26th November, 1947.\\nSince then, the process of budget \\nhas evolved and emerged as a \\ncrucial tool for Public Finance \\nManagement and reflect the \\nstrength of our democratic'), Document(id='6ea55537-26bb-43ea-a793-acc885cce45b', metadata={'producer': 'Adobe PDF library 16.03', 'creator': 'Adobe Illustrator 26.0 (Windows)', 'creationdate': '2024-02-01T21:46:19+06:30', 'moddate': '2024-02-01T23:18:45+05:30', 'title': 'Budget 2024', 'source': './data/sample.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2', 'start_index': 1561}, page_content='schemes and priorities of government are announced, and                                                                 \\nallocations are made to several sectors.\\nPart B: It deals with Finance Bill, which contains taxation proposals such as income tax \\nrevisions and indirect taxes.\\nMajor budget documents: Apart from the Finance Minister‚Äôs Budget Speech, following documents \\nare presented to Parliament:\\nAnnual Financial Statement (under Article 112) ,\\nDemands for Grants (under Article 113),\\nFinance Bill (under article 110)\\nFiscal Policy Statements mandated under FRBM Act -\\nMacro-Economic Framework Statement.\\nMedium-Term Fiscal Policy cum Fiscal Policy Strategy Statement.\\nOther explanatory documents are also presented like:\\nExpenditure Budget\\nReceipt Budget\\nExpenditure Profile\\nBudget at a Glance\\nKey Features of Budget 2024-25\\nImplementation of Budget Announcements, 2023-24\\nUnion Interim Budget 2024-25')]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\"When will budget will implemented\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph to assemble LangChain components into full-featured applications. \n",
    "# LangGraph is a graph-based representation of LangChain components and their relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# RAG Application ( goal here is to write code for query chain)\n",
    "# retriver -> data source  \n",
    "# Rag using langgraph\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# graph state \n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent‚Äôs brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='ReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent‚Äôs working memory, up to three, to be used as context for querying LLM.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Chain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\\\{(x, y_i , r_i , z_i)\\\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\\\geq r_{n-1} \\\\geq \\\\dots \\\\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='To avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\nThe idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='In comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I‚Äôve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Short-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Maximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for fast MIPS:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='HNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. ‚Äúsix degrees of separation‚Äù feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can‚Äôt get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='FAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization.\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\\\tilde{x}_i$ such that the inner product $\\\\langle q, x_i \\\\rangle$ is as similar to the original distance of $\\\\angle q, \\\\tilde{x}_i$ as possible, instead of picking the closet quantization centroid points.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: Tool Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for ‚ÄúModular Reasoning, Knowledge and Language‚Äù, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of ‚Äúexpert‚Äù modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='They did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the ‚ÄúExternal APIs‚Äù section of Prompt Engineering.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='ChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\"), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='API-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent‚Äôs tool use capabilities at three levels:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='This benchmark evaluates the agent‚Äôs tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API‚Äôs description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user‚Äôs requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Case Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='One interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='inquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents‚Äô experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent‚Äôs behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent‚Äôs future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content=\"Prompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X's plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\"), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='GOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Commands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='You should only respond in JSON format as described below\\nResponse Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='},\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {\\n    \"role\": \"user\",'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='},\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='}\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='You will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code‚Äôs language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the ‚Äúentrypoint‚Äù file, then go to the ones that are imported by that file, and so on.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='FILENAME\\nCODE\\nYou will start with the ‚Äúentrypoint‚Äù file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='You always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='pytest\\ndataclasses'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Conversatin samples:\\n[\\n  {\\n    \"role\": \"system\",'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='\"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='},\\n #  ‚Ä¶ same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Assumptions:\\\\n1. Model: The model will contain the game\\'s data, such as level information, character states, and enemy positions.\\\\n2. View: The view will handle the game\\'s visuals, including rendering the game objects, backgrounds, and updating the display.\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\\n  },\\n  {\\n    \"role\": \"user\",'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='\"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\"'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Reliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). ‚ÄúLLM-powered Autonomous Agents‚Äù. Lil‚ÄôLog. https://lilianweng.github.io/posts/2023-06-23-agent/.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Or\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. ‚ÄúChain of thought prompting elicits reasoning in large language models.‚Äù NeurIPS 2022\\n[2] Yao et al. ‚ÄúTree of Thoughts: Dliberate Problem Solving with Large Language Models.‚Äù arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. ‚ÄúChain of Hindsight Aligns Language Models with Feedback\\n‚Äú arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. ‚ÄúLLM+P: Empowering Large Language Models with Optimal Planning Proficiency‚Äù arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. ‚ÄúReAct: Synergizing reasoning and acting in language models.‚Äù ICLR 2023.\\n[6] Google Blog. ‚ÄúAnnouncing ScaNN: Efficient Vector Similarity Search‚Äù July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='[6] Google Blog. ‚ÄúAnnouncing ScaNN: Efficient Vector Similarity Search‚Äù July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. ‚ÄúReflexion: an autonomous agent with dynamic memory and self-reflection‚Äù arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. ‚ÄúIn-context Reinforcement Learning with Algorithm Distillation‚Äù ICLR 2023.\\n[10] Karpas et al. ‚ÄúMRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.‚Äù arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. ‚ÄúWebgpt: Browser-assisted question-answering with human feedback.‚Äù arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. ‚ÄúTALM: Tool Augmented Language Models‚Äù\\n[13] Schick et al. ‚ÄúToolformer: Language Models Can Teach Themselves to Use Tools.‚Äù arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='[13] Schick et al. ‚ÄúToolformer: Language Models Can Teach Themselves to Use Tools.‚Äù arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. ‚ÄúAPI-Bank: A Benchmark for Tool-Augmented LLMs‚Äù arXiv preprint arXiv:2304.08244 (2023).\\n[16] Shen et al. ‚ÄúHuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace‚Äù arXiv preprint arXiv:2303.17580 (2023).\\n[17] Bran et al. ‚ÄúChemCrow: Augmenting large-language models with chemistry tools.‚Äù arXiv preprint arXiv:2304.05376 (2023).\\n[18] Boiko et al. ‚ÄúEmergent autonomous scientific research capabilities of large language models.‚Äù arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. ‚ÄúGenerative Agents: Interactive Simulacra of Human Behavior.‚Äù arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer')]\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "print(all_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['79b91d64-0753-4afe-9dc3-52c3efdc23c3',\n",
       " '9e82247a-0087-49b2-b4c5-a8f6ac2585a5',\n",
       " 'e68401f2-29fe-4aa0-8729-5629ab080f40',\n",
       " '7ba5fb59-3000-4d1d-a987-5e862c6b3957',\n",
       " '083e3b83-3294-40ba-aa97-cb3fb68d7c03',\n",
       " '6ea2b9bf-8444-4de2-82a1-c0c62f97493e',\n",
       " '9506d0cb-03b3-4d0a-a3aa-96b8ed7d4d7a',\n",
       " '4a653f13-b276-47b8-8af2-3654a8509c35',\n",
       " '2f88820e-71b6-4a0b-a487-3b8182ba21c8',\n",
       " 'cff71238-e22b-409a-a1ad-325422cf83c1',\n",
       " '7a5d4474-f164-4b94-bc57-927f2c26ff44',\n",
       " '5c39488f-507b-4753-9635-ed22c434e061',\n",
       " '85170118-b8b0-49d8-a365-221a05cf4204',\n",
       " '36392275-cd55-49a6-8b37-585d02e6f7ca',\n",
       " 'e3d99418-4d5f-4795-bf3b-2429b89fcd0c',\n",
       " 'baf6292d-0bc2-46a0-9f68-68db830d65ce',\n",
       " 'f48a7cc6-90ec-47e7-b22e-b797c2d24cd3',\n",
       " '84d1aff1-0c2b-43d2-adcd-d5923c3d86c4',\n",
       " '3ef523b6-334d-43aa-9c71-031f5c45bba1',\n",
       " '6c469aff-7c8a-4d96-8e22-74d2fd14410a',\n",
       " '614324be-2803-4e68-82d4-c16383c4971e',\n",
       " '0b075543-1855-4469-b0f9-6ed5f0e97eef',\n",
       " '0f3ed48a-f0d6-454c-9b8a-27aae70c1614',\n",
       " 'efe6116f-f885-4413-b328-2541961e786b',\n",
       " 'e31e15d7-fa6b-4314-a98e-527629dac37d',\n",
       " '1a59d1b1-8e8a-4972-afe7-a9722c428aae',\n",
       " 'f076764d-5712-4ead-a00c-0b643564e0fc',\n",
       " '745c28f3-195f-4d0b-bd26-102d377074db',\n",
       " 'e42df683-2eb0-4173-bd9a-0057756267ea',\n",
       " '683e0e4f-2b5e-40d5-8f8c-d76dc48c1f9f',\n",
       " '5dd65a47-a98c-46a4-a853-17eee7cd9de3',\n",
       " '9359700b-d4d9-4df2-a852-5b2e8892df5f',\n",
       " 'b2da36f7-b4b9-4943-a75f-8a12c40c2e3e',\n",
       " '8a3a6848-b482-4e78-aed9-bf8aa34aeddf',\n",
       " '8c97ee65-a5b0-4a43-9e31-812a80985895',\n",
       " 'b7801e5f-6715-4efc-abdd-a285f18b8472',\n",
       " '61841990-3231-4d5c-8ee4-f1326ca2dcc9',\n",
       " '03c678ca-cb5e-49f0-94e3-3d4b7cabffe9',\n",
       " 'fd913b63-b08c-49da-b6d4-5f5b17a8770d',\n",
       " '20afa70b-8a07-41b3-836b-ed1f2dc19898',\n",
       " '8fc6629f-dc41-4aaf-91d4-51bf10a0dfed',\n",
       " 'eaac8a63-3e77-4cd8-a01d-4b3de1b9fb48',\n",
       " '9ab07a2d-a3fc-4d31-b785-48b6b87598b5',\n",
       " 'a24af2d5-2816-4d6f-b8f7-84c81a029e43',\n",
       " '91edda17-5e24-4852-9215-bb2cddcccd21',\n",
       " 'b935497a-62f2-41c5-82ad-ac1f8dc19325',\n",
       " '2ca81662-0a34-49a5-ba51-5a6fb86017ff',\n",
       " 'd9a5269c-9c99-4ced-baa7-e8fe544db5a6',\n",
       " '4f328b8b-cb8f-44b3-965d-9843dd286b1a',\n",
       " '8989e777-be05-4179-86b7-30147e10cd62',\n",
       " 'ee7d5ee3-dee7-4bb5-9b2e-867ad026ff73',\n",
       " 'ed96187a-a6e3-47a1-a14b-832aacfd1122',\n",
       " 'f4d99c51-287f-4b97-872e-8d0eabf02a3e',\n",
       " '7047e1c5-a14c-4318-b842-14920aa2cd9e',\n",
       " '3313dc27-9d64-42c0-974f-49028abce6ee',\n",
       " '238872f4-f2bf-46bc-8a1b-90c85ba7d416',\n",
       " 'ba5d708d-af95-4c23-bf5e-dd8d829b027a',\n",
       " 'f7c42b56-3cd7-479f-9a7b-6ce075908c19',\n",
       " 'bbd52f7f-2d4f-4eff-ba03-8574de5130f8',\n",
       " '21e1488e-f52d-4cf1-a3a8-778ac02ccee5',\n",
       " 'c1e3ebf2-d3d9-4ce6-8415-183ff3c1bda4',\n",
       " '23f244c3-0519-4650-97f8-7f671137152d',\n",
       " '8113e6aa-bdaa-4967-a3c8-5bfe96829f45',\n",
       " 'a3bbef46-1e25-4e0d-adc3-b03d8e863237',\n",
       " 'a3ab83a8-f690-432a-92f3-6aa607f0939e',\n",
       " 'e69b015a-ba97-400f-b8f5-59382a345298']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\choud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langsmith\\client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# concept of prompt templating\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Decomposition is the process of breaking down a complex task into smaller, more manageable steps. This is often achieved through techniques like Chain of Thought (CoT), where the model is prompted to \"think step by step\" and by using specific instructions tailored to the task. It may involve multiple reasoning possibilities or human inputs to facilitate clearer planning and execution.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
